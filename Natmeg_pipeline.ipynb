{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import mne\n",
    "from mne.preprocessing import create_ecg_epochs, create_eog_epochs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import os.path as op\n",
    "import matplotlib\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mne.coreg import Coregistration\n",
    "from mne.datasets import fetch_fsaverage\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse, apply_inverse_epochs\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "from scipy import stats as stats\n",
    "from mne.stats import spatio_temporal_cluster_1samp_test, summarize_clusters_stc\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import shapiro, levene, ttest_ind, f_oneway\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from nilearn.plotting import plot_connectome"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading MEG data (movement corrected) and defining events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading subject IDs (subject 697 cant be loaded and subject 859 has different dev_head_t during the two recordings)\n",
    "subjects_fname = '/Users/payamsadeghishabestari/KI_MEG/sub_date.txt'\n",
    "subject_ids = np.loadtxt(fname=subjects_fname, delimiter=',', skiprows=1, usecols=1)\n",
    "subject_ids = [int(s_id) for s_id in subject_ids]\n",
    "\n",
    "# find all the subject folders\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/meg_rec_tinmeg1' \n",
    "folders_list = []\n",
    "for folder in sorted(os.listdir(directory)): ## iterate over folders in that directory\n",
    "    f = os.path.join(directory, folder)\n",
    "    if os.path.isdir(f): ## select only folders\n",
    "        folders_list.append(f)\n",
    "\n",
    "# create a dictionary of subjects with their files\n",
    "files_dict = {}\n",
    "for subject_id in subject_ids:\n",
    "    for folder in folders_list:\n",
    "        if f'{subject_id}' in folder:\n",
    "            f = os.path.join(folder, sorted(os.listdir(folder))[-1])\n",
    "            files_dict[f'{subject_id}'] = [f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating event dictionary\n",
    "# tinmeg1\n",
    "keys = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95',\n",
    "        'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95',\n",
    "        'GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240',\n",
    "        'GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240',\n",
    "        'GO_60', 'GO_70']\n",
    "values = [40968, 36872, 34824, 33800, 33288, 33032,\n",
    "        36876, 34828, 33804, 33292, 33036,\n",
    "        49800, 49736, 49704, 49688,\n",
    "        49804, 49740, 49708, 49692,\n",
    "        16386, 16390]\n",
    "events_dict_tinmeg1 = {}\n",
    "for key, value in zip(keys, values):\n",
    "        events_dict_tinmeg1[key] = value\n",
    "\n",
    "# tinmeg2\n",
    "keys = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "        'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "        'GPP_08', 'GPG_08', 'PO_08', 'GO_08',\n",
    "        'GPP_30', 'GPG_30', 'PO_30', 'GO_30',\n",
    "        'GPP_33', 'GPG_33', 'PO_33', 'GO_33',\n",
    "        'GPP_38', 'GPG_38', 'PO_38', 'GO_38',\n",
    "        'GPP_80', 'GPG_80', 'PO_80', 'GO_80',\n",
    "        'GPP_83', 'GPG_83', 'PO_83', 'GO_83',\n",
    "        'GPP_88', 'GPG_88', 'PO_88', 'GO_88']\n",
    "values = [1, 2, 4, 8, 16, 32,\n",
    "        49, 50, 52, 56,\n",
    "        33, 34, 36, 40,\n",
    "        193, 194, 196, 200,\n",
    "        241, 242, 244, 248,\n",
    "        225, 226, 228, 232,\n",
    "        129, 130, 132, 136,\n",
    "        177, 178, 180, 184,\n",
    "        161, 162, 164, 168]\n",
    "events_dict_tinmeg2 = {}\n",
    "for key, value in zip(keys, values):\n",
    "        events_dict_tinmeg2[key] = value\n",
    "\n",
    "#tinmeg3\n",
    "keys = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "        'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "        'GPP_08', 'GPG_08', 'PO_08', 'GO_08']\n",
    "values = [1, 2, 4, 8, 16, 32,\n",
    "        49, 50, 52, 56,\n",
    "        33, 34, 36, 40]\n",
    "events_dict_tinmeg3 = {}\n",
    "for key, value in zip(keys, values):\n",
    "        events_dict_tinmeg3[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maxwell Filtering and environmental noise reduction (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the empty room recordings before and after exp\n",
    "fname_empty_before = '/Users/payamsadeghishabestari/KI_MEG/697/empty_room_before.fif'\n",
    "fname_empty_after = '/Users/payamsadeghishabestari/KI_MEG/697/empty_room_after.fif'\n",
    "raw_empty_before = mne.io.read_raw_fif(fname=fname_empty_before, preload=True, allow_maxshield=True, verbose=False)\n",
    "raw_empty_after = mne.io.read_raw_fif(fname=fname_empty_after, preload=True, allow_maxshield=True, verbose=False)\n",
    "\n",
    "# compute projections for empty room recordings and concatenate them\n",
    "raw_empty_before.del_proj()\n",
    "raw_empty_after.del_proj()\n",
    "empty_room_before_projs = mne.compute_proj_raw(raw_empty_before, n_grad=2, n_mag=2, verbose=False)\n",
    "empty_room_after_projs = mne.compute_proj_raw(raw_empty_after, n_grad=2, n_mag=2, verbose=False)\n",
    "extended_proj = list(np.concatenate((np.array(empty_room_before_projs), np.array(empty_room_after_projs))))\n",
    "\n",
    "# load the experiment recording\n",
    "fname = '/Users/payamsadeghishabestari/KI_MEG/697/tinmeg1-1.fif'\n",
    "raw = mne.io.read_raw_fif(fname=fname, preload=True, allow_maxshield=True, verbose=False)\n",
    "\n",
    "# estimating continous head movement\n",
    "chpi_freqs, ch_idx, chpi_codes = mne.chpi.get_chpi_info(info=raw.info)\n",
    "chpi_amplitudes = mne.chpi.compute_chpi_amplitudes(raw)\n",
    "chpi_locs = mne.chpi.compute_chpi_locs(raw.info, chpi_amplitudes)\n",
    "head_pos = mne.chpi.compute_head_pos(raw.info, chpi_locs, verbose=True)\n",
    "\n",
    "# find bad channels\n",
    "noisy_chs, flat_chs = mne.preprocessing.find_bad_channels_maxwell(raw, head_pos=head_pos, verbose=True)\n",
    "bads = raw.info[\"bads\"] + noisy_chs + flat_chs\n",
    "raw.info[\"bads\"] = bads\n",
    "\n",
    "# apply movement corection and time-signal space seperation\n",
    "raw_sss = mne.preprocessing.maxwell_filter(raw, head_pos=head_pos, st_fixed=True,\n",
    "                                            extended_proj=extended_proj,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/Users/payamsadeghishabestari/KI_MEG/697/tinmeg1.fif'\n",
    "raw = mne.io.read_raw_fif(fname=fname, preload=True, allow_maxshield=True, verbose=False)\n",
    "\n",
    "# estimating continous head movement\n",
    "chpi_freqs, ch_idx, chpi_codes = mne.chpi.get_chpi_info(info=raw.info)\n",
    "chpi_amplitudes = mne.chpi.compute_chpi_amplitudes(raw)\n",
    "chpi_locs = mne.chpi.compute_chpi_locs(raw.info, chpi_amplitudes)\n",
    "head_pos = mne.chpi.compute_head_pos(raw.info, chpi_locs, verbose=True)\n",
    "\n",
    "# find bad channels\n",
    "noisy_chs, flat_chs = mne.preprocessing.find_bad_channels_maxwell(raw, head_pos=head_pos, verbose=True)\n",
    "bads = raw.info[\"bads\"] + noisy_chs + flat_chs\n",
    "raw.info[\"bads\"] = bads\n",
    "\n",
    "# apply movement corection and time-signal space seperation\n",
    "raw_sss = mne.preprocessing.maxwell_filter(raw, head_pos=head_pos, st_fixed=True, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 250\n",
    "(l_freq, h_freq) = (0.1, 40)\n",
    "(tmin, tmax) = (-0.3, 0.3) # baseline period of 300 ms\n",
    "reject_criteria = dict(grad=4000e-13, mag=4e-12, eog=250e-6)    # T/m  # T  # V\n",
    "flat_criteria = dict(mag=1e-15, grad=1e-13)  # 1 fT  # 1 fT/cm  (adding flat option to eog)\n",
    "subjects = list(files_dict.keys())[:]\n",
    "\n",
    "# reading the MEG file\n",
    "for subject in tqdm(subjects): \n",
    "    start_time = time.time()\n",
    "    print(subject)\n",
    "    print('reading the MEG file, be patient ...')\n",
    "    fname = files_dict[subject][0]\n",
    "    raw = mne.io.read_raw_fif(fname=fname, preload=True, allow_maxshield=True, verbose=False)\n",
    "    #if raw.last_samp / raw.info['sfreq'] < 3000:\n",
    "    #    raise ValueError(f'All .fif files might not be loaded for subject {subject}')\n",
    "    events_orig = mne.find_events(raw, stim_channel=None, min_duration=0.005, shortest_event=1, uint_cast=True, verbose=False) # min_duration = 0\n",
    "\n",
    "    # delay compensation for tinmeg1 data\n",
    "    #delay = int((50 / 1000) * raw.info['sfreq']) # 50 ms delay \n",
    "    #po_ids = list(events_dict_tinmeg3.values())[:11] # only PO triggers\n",
    "    #for row in range(len(events_orig)):\n",
    "    #    if events_orig[row][2] in po_ids:\n",
    "    #        events_orig[row][0] = events_orig[row][0] - delay\n",
    "\n",
    "    # resampling and filtering the data\n",
    "    print('resampling and filtering the data, be patient, will last a while ...')\n",
    "    raw, events = raw.resample(sfreq=sfreq, events=events_orig, verbose=False)\n",
    "    raw = raw.filter(l_freq=l_freq, h_freq=h_freq, verbose=False) \n",
    "\n",
    "    # creating ECG and EOG evoked responses\n",
    "    ecg_evoked_meg,  ecg_evoked_grad = create_ecg_epochs(raw,\n",
    "                                    verbose=False).average().apply_baseline(baseline=(None, -0.2),\n",
    "                                    verbose=False).plot_joint(picks=['meg', 'grad'], show=False)\n",
    "    eog_evoked_meg,  eog_evoked_grad = create_eog_epochs(raw,\n",
    "                                    verbose=False).average().apply_baseline(baseline=(None, -0.2),\n",
    "                                    verbose=False).plot_joint(picks=['meg', 'grad'], show=False)\n",
    "\n",
    "    # computing ICA and remove ECG, saccade and muscle artifacts (if any) and interpolating (if any)\n",
    "    print('computing ICA (this might take a while) ...')\n",
    "    ica = mne.preprocessing.ICA(n_components=0.95, max_iter=800, method='infomax',\n",
    "                                random_state=42, fit_params=dict(extended=True)) \n",
    "    ica.fit(raw, verbose=False) \n",
    "    ecg_indices, ecg_scores = ica.find_bads_ecg(raw, method=\"ctps\", measure='zscore', verbose=False)\n",
    "    if len(ecg_indices) > 0:\n",
    "        ecg_component = ica.plot_properties(raw, picks=ecg_indices, verbose=False, show=False)\n",
    "    emg_indices, emg_scores = ica.find_bads_muscle(raw, verbose=False)\n",
    "    if len(emg_indices) > 0:\n",
    "        emg_component = ica.plot_properties(raw, picks=emg_indices, verbose=False, show=False)\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(raw, ch_name='EOG002') \n",
    "    if len(eog_indices) > 0:\n",
    "        eog_component = ica.plot_properties(raw, picks=eog_indices, verbose=False, show=False)\n",
    "\n",
    "    exclude_idxs = ecg_indices + emg_indices\n",
    "    ica.apply(raw, exclude=exclude_idxs, verbose=False)\n",
    "    raw.interpolate_bads(verbose=False)\n",
    "\n",
    "    # event dict selection, epoching and dropping bad epochs \n",
    "    #if fname[-43] == '1':\n",
    "    #    events_dict = events_dict_tinmeg1\n",
    "    #if fname[-43] == '2':\n",
    "    #    events_dict = events_dict_tinmeg2\n",
    "    #if fname[-43] == '3':\n",
    "    #    events_dict = events_dict_tinmeg3\n",
    "    \n",
    "    events_dict = events_dict_tinmeg1\n",
    "    print('Epoching data ...')\n",
    "    epochs = mne.Epochs(raw, events, event_id=events_dict, tmin=tmin, tmax=tmax, baseline=(None, 0),\n",
    "                        reject=None, flat=None, preload=True, verbose=False) \n",
    "    dropped_epochs_fig = epochs.plot_drop_log(color=(0.6, 0.2, 0.4), width=0.4, show=False)\n",
    "\n",
    "    # creating a report\n",
    "    report = mne.Report(title=f'report_subject_{subject}', verbose=False)\n",
    "    report.add_raw(raw=raw, title='recording after preprocessing', butterfly=False, psd=False) \n",
    "    report.add_figure(fig=ecg_evoked_meg, title='ECG evoked MEG', image_format='PNG')\n",
    "    report.add_figure(fig=ecg_evoked_grad, title='ECG evoked Gradiometer', image_format='PNG')\n",
    "    report.add_figure(fig=eog_evoked_meg, title='EOG evoked MEG', image_format='PNG')\n",
    "    report.add_figure(fig=eog_evoked_grad, title='EOG evoked Gradiometer', image_format='PNG')\n",
    "    if len(ecg_indices) > 0:\n",
    "        report.add_figure(fig=ecg_component, title='ECG component', image_format='PNG')\n",
    "    if len(emg_indices) > 0:\n",
    "        report.add_figure(fig=emg_component, title='EMG component', image_format='PNG')\n",
    "    if len(eog_indices) > 0:\n",
    "        report.add_figure(fig=eog_component, title='EOG component (saccade)', image_format='PNG')    \n",
    "    report.add_figure(fig=dropped_epochs_fig, title='Dropped Epochs', image_format='PNG')\n",
    "    \n",
    "    # saving report and epochs\n",
    "    \n",
    "    fname_report = f'/Users/payamsadeghishabestari/KI_MEG/pending files/{subject}/report_subject_{subject}.html'\n",
    "    fname_epoch = f'/Users/payamsadeghishabestari/KI_MEG/pending files/{subject}/epochs_subject_{subject}-epo.fif'\n",
    "    report.save(fname=fname_report, open_browser=False, overwrite=True, verbose=False)\n",
    "    epochs.save(fname=fname_epoch, overwrite=True, verbose=False)\n",
    "    print(f'elapsed time for subject {subject} was {time.time() - start_time}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating, creating evoked objects and grand averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epochs dictionary (some needs concatenating)\n",
    "epochs_folder = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg1'\n",
    "epochs_file = {}\n",
    "for f in sorted(os.listdir(epochs_folder)):\n",
    "    file = os.path.join(epochs_folder, f)\n",
    "    if file.endswith(\"-epo.fif\") and '697' not in file and '750' not in file and '853' not in file and '841' not in file:\n",
    "        epochs_file[f'{file[-11:-8]}'] = file\n",
    "\n",
    "# compute evoked objects, and making grand average dictionary\n",
    "evs = []\n",
    "for ep_f in tqdm(list(epochs_file.values())):\n",
    "    evs.append(mne.read_epochs(fname=ep_f, verbose=False).average(picks=['meg', 'eog'], by_event_type=True))\n",
    "\n",
    "grnd_ev_dict = {}\n",
    "for stim_idx, stim in enumerate(list(events_dict_tinmeg1.keys())):\n",
    "    evs_stim = []\n",
    "    for ev in evs:\n",
    "        evs_stim.append(ev[stim_idx])\n",
    "    grnd_ev_dict[stim] = evs_stim\n",
    "\n",
    "grand_ev_dict = {}\n",
    "for stim in list(grnd_ev_dict.keys()):\n",
    "    grand_ev_dict[stim] = mne.grand_average(grnd_ev_dict[stim])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check EOG response (Niklas thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PO at 60 dB\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 5))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "colors = ['purple', 'brown', 'blue', 'orange', 'red', 'green']\n",
    "for stim, color in zip(stims, colors):\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6, label=stim)\n",
    "axs.axvspan(50, 220, alpha=0.4, color='lightcyan')\n",
    "axs.legend(fontsize=9, frameon=False)\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "axs.grid(axis='x', color='k', linestyle='--', linewidth=0.5)\n",
    "axs.vlines(0, -50, 10, colors='black',linestyles='--')\n",
    "axs.set_ylabel(f'EOG amplitude at 60 dB (µv)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "\n",
    "#### GP at 60 dB\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 5))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "colors = ['blue', 'orange', 'red', 'green']\n",
    "for stim, color in zip(stims, colors):\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6, label=stim)\n",
    "axs.axvspan(50, 220, alpha=0.4, color='lightcyan')\n",
    "axs.legend(fontsize=9, frameon=False)\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "axs.grid(axis='x', color='k', linestyle='--', linewidth=0.5)\n",
    "axs.vlines(0, -50, 10, colors='black',linestyles='--')\n",
    "axs.set_ylabel(f'EOG amplitude at 60 dB (µv)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_xlim([-300, 300])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check ERFs (Niklas thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate chanels on left and right\n",
    "info_ch = evs[0][0].info['chs']\n",
    "meg_chs_right = []; meg_chs_left = []\n",
    "grad_chs_right = []; grad_chs_left = []\n",
    "for i in range(len(info_ch)):\n",
    "    if info_ch[i]['unit'] == 112: # meg code\n",
    "        if info_ch[i]['loc'][0] > 0:\n",
    "            meg_chs_right.append(info_ch[i]['ch_name'])\n",
    "        if info_ch[i]['loc'][0] < 0:\n",
    "            meg_chs_left.append(info_ch[i]['ch_name'])\n",
    "    if info_ch[i]['unit'] == 201: # grad code\n",
    "        if info_ch[i]['loc'][0] > 0:\n",
    "            grad_chs_right.append(info_ch[i]['ch_name'])\n",
    "        if info_ch[i]['loc'][0] < 0:\n",
    "            grad_chs_left.append(info_ch[i]['ch_name'])\n",
    "\n",
    "# select the left/ channels with largest ptp amplitude\n",
    "ev_data_left = grand_ev_dict['PO60_70'].get_data(picks=grad_chs_left)\n",
    "ev_data_right = grand_ev_dict['PO60_70'].get_data(picks=grad_chs_right)\n",
    "max_values = []\n",
    "for ch_idx in range(len(ev_data_left)):\n",
    "    max_values.append(ev_data_left[ch_idx][50:150].max())\n",
    "ch_max_left = grad_chs_left[np.argmax(np.array(max_values))]\n",
    "max_values = []\n",
    "for ch_idx in range(len(ev_data_right)):\n",
    "    max_values.append(ev_data_right[ch_idx][50:150].max())\n",
    "ch_max_right = grad_chs_right[np.argmax(np.array(max_values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PO 60 dB\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 3))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "alphas = np.linspace(0.2, 1, 6)\n",
    "for stim, alpha in zip(stims, alphas):\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks=ch_max_left)[0] * 1e13, color='#1f77b4', alpha=alpha, label=stim)\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks=ch_max_right)[0] * 1e13, color='red', alpha=alpha, label=stim)\n",
    "axs.axvspan(50, 150, alpha=0.4, color='lightcyan')\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "axs.grid(axis='x', color='k', linestyle='--', linewidth=0.5)\n",
    "axs.set_ylabel(f'ERF amplitude at 60 dB (fT/m)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_xlim([-300, 300])\n",
    "\n",
    "# GP 60 dB\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 3))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "dc_shifts = [0, 50, 100, 150]\n",
    "for stim, dc_shift in zip(stims, dc_shifts):\n",
    "    axs.plot(time_array, dc_shift + grand_ev_dict[stim].get_data(picks=ch_max_left)[0] * 1e13, color='#1f77b4', label=stim)\n",
    "    axs.plot(time_array, dc_shift + grand_ev_dict[stim].get_data(picks=ch_max_right)[0] * 1e13, color='red', label=stim)\n",
    "axs.axvspan(50, 150, alpha=0.4, color='lightcyan')\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "axs.grid(axis='x', color='k', linestyle='--', linewidth=0.5)\n",
    "axs.set_ylabel(f'Relative values')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_xlim([-300, 300])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Notes:\n",
    "# 1. check with and without ICA, since we didnt remove blink, however makes sense to proceed without applying ICA\n",
    "# 2. before the time 0, we have an activity at GP series so its not a good idea to use epochs baseline as a time span to estimate noise covariance\n",
    "# the good way to estimate the noise cov is to use only PO series baseline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cortical surface reconstruction (+bem, +head_model) with FreeSurfer (as an example for one subject)\n",
    "$ export FREESURFER_HOME=/Applications/freesurfer/7.4.1\n",
    "$ export SUBJECTS_DIR=$FREESURFER_HOME/subjects\n",
    "$ source $FREESURFER_HOME/SetUpFreeSurfer.sh\n",
    "$ recon-all -s 0863 -i /Users/payamsadeghishabestari/KI_MEG/MRI/0863/00000003/00000001.dcm \n",
    "$ recon-all -all -subjid 0863\n",
    "\n",
    "# setting up watershed BEM files \n",
    "subject = '0863'\n",
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "mne.bem.make_watershed_bem(subject, subjects_dir=None,\n",
    "                            overwrite=False, volume='T1', atlas=False,\n",
    "                            gcaatlas=False, preflood=None, show=False,\n",
    "                            copy=True, T1=None, brainmask='ws.mgz', verbose=None)\n",
    "\n",
    "# mri_convert /Users/payamsadeghishabestari/nilearn_data/schaefer_2018/Schaefer2018_400Parcels_7Networks_order_FSLMNI152_1mm.nii.gz $SUBJECTS_DIR/0750/mri/schaefer_atlas.mgz\n",
    "# bbregister --s 0750 --mov $SUBJECTS_DIR/0750/mri/schaefer_atlas.mgz --t1 --reg $SUBJECTS_DIR/0750/schaefer.reg\n",
    "# mri_aparc2aseg --s 0750 --annot $SUBJECTS_DIR/0750/mri/schaefer_atlas.mgz\n",
    "# mri_label2vol --seg $SUBJECTS_DIR/0750/mri/aparc+aseg.mgz --temp $SUBJECTS_DIR/0750/mri/orig.mgz --o schaefer_combined.mgz --reg schaefer.reg --fillthresh 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# po_stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95'] # for tinmeg1\n",
    "po_stims = ['PO_00', 'PPP_00', 'PO_03', 'PO_08'] # tinmeg3\n",
    "# po_stims = ['PO_00', 'PO_03', 'PO_08', 'PO_30', 'PO_33', 'PO_38', 'PO_80', 'PO_83', 'PO_88'] # tinmeg2\n",
    "\n",
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "method = \"dSPM\"\n",
    "snr = 3.0\n",
    "lambda2 = 1.0 / snr**2\n",
    "\n",
    "for subject in np.array(list(epochs_file.keys()))[[11,12]]: # list(epochs_file.keys())\n",
    "    \n",
    "    subject_idx = list(epochs_file.keys()).index(subject)\n",
    "    report = mne.Report(title=f'source_localization_report_subject_{subject}', verbose=False)\n",
    "    \n",
    "    # Setting up the surface source space\n",
    "    print(f'Setting up bilateral hemisphere surface-based source space with subsampling for subject {subject} ...')\n",
    "    src = mne.setup_source_space(f'{subject}', spacing=\"oct6\", subjects_dir=subjects_dir, n_jobs=-1, verbose=None)\n",
    "\n",
    "    # Setting up the boundary-element model (BEM) \n",
    "    print(f'Creating a BEM model for subject ...')\n",
    "    bem_model = mne.make_bem_model(subject=f'{subject}', ico=4, subjects_dir=subjects_dir, verbose=False)  \n",
    "    bem = mne.make_bem_solution(bem_model, verbose=False)\n",
    "    report.add_bem(subject=f'{subject}', subjects_dir=subjects_dir, title=\"MRI & BEM\", decim=10, width=512)\n",
    "\n",
    "    # Aligning coordinate frame (coregistration MEG-MRI)\n",
    "    print(f'Coregistering MRI with a subjects head shape ...')\n",
    "    # info = grnd_ev_dict['PO60_80'][subject_idx].info # tinmeg1\n",
    "    info = grnd_ev_dict['PO_00'][subject_idx].info # tinmeg3\n",
    "    coreg = Coregistration(info, f'{subject}', subjects_dir, fiducials='auto')\n",
    "    coreg.fit_fiducials(verbose=False)\n",
    "    coreg.fit_icp(n_iterations=40, nasion_weight=2.0, verbose=False) # refining with ICP\n",
    "    coreg.omit_head_shape_points(distance=5.0 / 1000) # omitting bad points (larger than 5mm)\n",
    "    coreg.fit_icp(n_iterations=40, nasion_weight=10, verbose=False) # final fitting\n",
    "    fname_trans = f'/Users/payamsadeghishabestari/KI_MEG/trans/{subject}-trans.fif'\n",
    "    mne.write_trans(fname_trans, coreg.trans, overwrite=True, verbose=False)\n",
    "    report.add_trans(trans=fname_trans, info=info, subject=f'{subject}',\n",
    "                    subjects_dir=subjects_dir, alpha=1.0, title=\"Co-registration\")\n",
    "\n",
    "    # Computing the forward solution\n",
    "    print(f'Computing the forward solution ...')\n",
    "    fwd = mne.make_forward_solution(info, trans=coreg.trans, src=src, bem=bem, meg=True,\n",
    "                                    eeg=False, mindist=5.0, n_jobs=None, verbose=False)\n",
    "\n",
    "    # Computing the regularized noise-covariance matrix (consider the notes)\n",
    "    print(f'Estimate the noise covariance of the recording ...')\n",
    "    epochs = mne.read_epochs(fname=epochs_file[subject], verbose=False)\n",
    "    noise_cov = mne.compute_covariance(epochs[po_stims], tmax=0.0, method=(\"empirical\", \"shrunk\"),\n",
    "                                        verbose=False) # using the epochs baseline \n",
    "    \n",
    "    # Computing the minimum-norm inverse solution\n",
    "    print(f'Computing the minimum-norm inverse solution ...')\n",
    "    inverse_operator = make_inverse_operator(info, fwd, noise_cov, loose=0.2, depth=0.8, verbose=False)\n",
    "\n",
    "    # Compute source estimate object\n",
    "    print(f'Computing and saving the source estimate object ...')\n",
    "    for key_id in list(grnd_ev_dict.keys()):\n",
    "        stc = apply_inverse(grnd_ev_dict[key_id][subject_idx], inverse_operator, lambda2, method=method, pick_ori=None,\n",
    "                            return_residual=False, verbose=False)\n",
    "        fname_stc = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg3/{subject}_{key_id}'\n",
    "        stc.save(fname=fname_stc, overwrite=True, verbose=False)\n",
    "\n",
    "    # saving report\n",
    "    fname_report = f'/Users/payamsadeghishabestari/KI_MEG/reports/source_localization_report_subject_{subject}.html'\n",
    "    report.save(fname=fname_report, open_browser=False, overwrite=True, verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphing to freesurfer template brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "fname_fsaverage_src = '/Users/payamsadeghishabestari/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg3' \n",
    "src_to = mne.read_source_spaces(fname_fsaverage_src)\n",
    "\n",
    "# iterate over files in that directory\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\"): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "\n",
    "# morphing from oct-6 to ico-5 at fsaverage\n",
    "for stc_file in tqdm(stc_files_list):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject=f'{stc_file[50:54]}')\n",
    "    \n",
    "    morph = mne.compute_source_morph(stc, subject_from=f'{stc_file[50:54]}',\n",
    "                                    subject_to=\"fsaverage\", subjects_dir=subjects_dir,\n",
    "                                    src_to=src_to)\n",
    "    stc_morph = morph.apply(stc)\n",
    "    fname_stc_morph = ''.join([stc_file[:49], '_morphed', stc_file[49:]])\n",
    "    stc_morph.save(fname=fname_stc_morph, overwrite=True, verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single subject\n",
    "subject = '859'\n",
    "event = 'PO60_90'\n",
    "fname_stc = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1/{subject}_{event}-rh.stc'\n",
    "stc = mne.read_source_estimate(fname=fname_stc, subject=f'0{subject}')\n",
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "colormap = \"viridis\"\n",
    "clim = dict(kind=\"value\", lims=[4, 8, 12])\n",
    "fig_brain = stc.plot(views=\"lat\", hemi=\"split\", size=(800, 400), subject=f'0{subject}',\n",
    "                    subjects_dir=subjects_dir, background=\"w\", colorbar=True, clim=clim,\n",
    "                    colormap=colormap, time_viewer=True, show_traces=True)\n",
    "fig_brain.add_annotation(\"aparc\", borders=True, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average of subjects\n",
    "event = 'GO_60'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event in f): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "data = []\n",
    "for stc_file in tqdm(stc_files_list):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data.append(stc.data)\n",
    "stc_average = mne.SourceEstimate(data=np.mean(np.array(data), axis=0), vertices=stc.vertices,\n",
    "                                tmin=stc.tmin, tstep=stc.tstep, subject='fsaverage')\n",
    "colormap = \"viridis\"\n",
    "clim = dict(kind=\"value\", lims=[4, 8, 12])\n",
    "fig_brain = stc_average.plot(views=\"lat\", hemi=\"split\", size=(800, 400), subject='fsaverage',\n",
    "                    subjects_dir=None, background=\"w\", colorbar=True, clim=clim,\n",
    "                    colormap=colormap, time_viewer=True, show_traces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average of subjects\n",
    "event1 = 'PO60_90'\n",
    "event2 = 'GO_60'\n",
    "event3 = 'GP60_i0'\n",
    "event4 = 'GP60_i60'\n",
    "event5 = 'GP60_i120'\n",
    "event6 = 'GP60_i240'\n",
    "subject = '853'\n",
    "\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_1 = []; stc_files_list_2 = []; stc_files_list_3 = []; stc_files_list_4 = []; stc_files_list_5 = []; stc_files_list_6 = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event1 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_1.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event2 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_2.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event3 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_3.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event4 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_4.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event5 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_5.append(f)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (event6 in f) and (subject in f): # or -rh\n",
    "        stc_files_list_6.append(f)\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(17, 2))\n",
    "ymax = 4\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_1):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[0].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[0].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[0].grid(axis='x'); axs[0].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_2):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[1].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[1].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[1].grid(axis='x'); axs[1].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_3):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[2].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[2].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[2].grid(axis='x'); axs[2].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_4):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[3].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[3].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[3].grid(axis='x'); axs[3].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_5):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[4].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[4].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[4].grid(axis='x'); axs[4].set_ylim([0, ymax])\n",
    "\n",
    "data_lh = []\n",
    "data_rh = []\n",
    "for stc_file in tqdm(stc_files_list_6):\n",
    "    stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "    data_lh.append(stc.lh_data)\n",
    "    data_rh.append(stc.rh_data)\n",
    "\n",
    "axs[5].plot(stc.times*1000, np.mean(np.mean(data_lh, axis=0), axis=0).T, color='#1f77b4')\n",
    "axs[5].plot(stc.times*1000, np.mean(np.mean(data_rh, axis=0), axis=0).T, color='#ff7f0e')\n",
    "axs[5].grid(axis='x'); axs[5].set_ylim([0, ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting all subjects * conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = '853'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (subject in f): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "\n",
    "event1 = 'PO60_90'\n",
    "event2 = 'GO_60'\n",
    "event3 = 'GP60_i0'\n",
    "event4 = 'GP60_i60'\n",
    "event5 = 'GP60_i120'\n",
    "event6 = 'GP60_i240'\n",
    "fig, axs = plt.subplots(1, 6, figsize=(17, 2))\n",
    "ymax = 5\n",
    "for stc_file in stc_files_list:\n",
    "    if event1 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[0].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[0].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[0].grid(axis='x'); axs[0].set_ylim([0, ymax])\n",
    "    if event2 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[1].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[1].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[1].grid(axis='x'); axs[1].set_ylim([0, ymax])\n",
    "    if event3 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[2].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[2].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[2].grid(axis='x'); axs[2].set_ylim([0, ymax])\n",
    "    if event4 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[3].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[3].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[3].grid(axis='x'); axs[3].set_ylim([0, ymax])\n",
    "    if event5 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[4].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[4].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[4].grid(axis='x'); axs[4].set_ylim([0, ymax])\n",
    "    if event6 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        axs[5].plot(stc.times*1000, np.mean(stc.lh_data, axis=0).T, color='#1f77b4')\n",
    "        axs[5].plot(stc.times*1000, np.mean(stc.rh_data, axis=0).T, color='#ff7f0e')\n",
    "        axs[5].grid(axis='x'); axs[5].set_ylim([0, ymax])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting time courses in transverstemporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = '863'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and (subject in f): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "\n",
    "event1 = 'PO60_90'\n",
    "event2 = 'GO_60'\n",
    "event3 = 'GP60_i0'\n",
    "event4 = 'GP60_i60'\n",
    "event5 = 'GP60_i120'\n",
    "event6 = 'GP60_i240'\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "bl_idx_rh = -1\n",
    "bl_idx_lh = -2\n",
    "mode = 'mean'\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(17, 2))\n",
    "ymax = 12\n",
    "for stc_file in stc_files_list:\n",
    "    if event1 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[0].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[0].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[0].grid(axis='x'); axs[0].set_ylim([0, ymax])\n",
    "    if event2 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[1].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[1].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[1].grid(axis='x'); axs[1].set_ylim([0, ymax])\n",
    "    if event3 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[2].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[2].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[2].grid(axis='x'); axs[2].set_ylim([0, ymax])\n",
    "    if event4 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[3].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[3].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[3].grid(axis='x'); axs[3].set_ylim([0, ymax])\n",
    "    if event5 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[4].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[4].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[4].grid(axis='x'); axs[4].set_ylim([0, ymax])\n",
    "    if event6 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stc_rh = stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False)\n",
    "        stc_lh = stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False)\n",
    "        axs[5].plot(stc.times*1000, stc_rh[0], color='#1f77b4')\n",
    "        axs[5].plot(stc.times*1000, stc_lh[0], color='#ff7f0e')\n",
    "        axs[5].grid(axis='x'); axs[5].set_ylim([0, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average in transtemporal\n",
    "subject = '863'\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\"): # or -rh\n",
    "        stc_files_list.append(f)\n",
    "\n",
    "event1 = 'PO60_90'\n",
    "event2 = 'GO_60'\n",
    "event3 = 'GP60_i0'\n",
    "event4 = 'GP60_i60'\n",
    "event5 = 'GP60_i120'\n",
    "event6 = 'GP60_i240'\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "bl_idx_rh = -1\n",
    "bl_idx_lh = -2\n",
    "mode = 'mean'\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(17, 2))\n",
    "ymax = 12\n",
    "stcs_rh_1 = []; stcs_lh_1 = []\n",
    "stcs_rh_2 = []; stcs_lh_2 = []\n",
    "stcs_rh_3 = []; stcs_lh_3 = []\n",
    "stcs_rh_4 = []; stcs_lh_4 = []\n",
    "stcs_rh_5 = []; stcs_lh_5 = []\n",
    "stcs_rh_6 = []; stcs_lh_6 = []\n",
    "\n",
    "for stc_file in stc_files_list:\n",
    "    if event1 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_1.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_1.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event2 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_2.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_2.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event3 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_3.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_3.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event4 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_4.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_4.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event5 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_5.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_5.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "    if event6 in stc_file:\n",
    "        stc = mne.read_source_estimate(fname=stc_file, subject='fsaverage')\n",
    "        stcs_rh_6.append(stc.extract_label_time_course(brain_labels[bl_idx_rh], src, mode=mode, verbose=False))\n",
    "        stcs_lh_6.append(stc.extract_label_time_course(brain_labels[bl_idx_lh], src, mode=mode, verbose=False))\n",
    "\n",
    "\n",
    "axs[0].plot(stc.times*1000, np.mean(np.array(stcs_rh_1),axis=0)[0], color='#1f77b4')\n",
    "axs[0].plot(stc.times*1000, np.mean(np.array(stcs_lh_1),axis=0)[0], color='#ff7f0e')\n",
    "axs[0].grid(axis='x'); axs[0].set_ylim([0, ymax])\n",
    "axs[1].plot(stc.times*1000, np.mean(np.array(stcs_rh_2),axis=0)[0], color='#1f77b4')\n",
    "axs[1].plot(stc.times*1000, np.mean(np.array(stcs_lh_2),axis=0)[0], color='#ff7f0e')\n",
    "axs[1].grid(axis='x'); axs[1].set_ylim([0, ymax])\n",
    "axs[2].plot(stc.times*1000, np.mean(np.array(stcs_rh_3),axis=0)[0], color='#1f77b4')\n",
    "axs[2].plot(stc.times*1000, np.mean(np.array(stcs_lh_3),axis=0)[0], color='#ff7f0e')\n",
    "axs[2].grid(axis='x'); axs[2].set_ylim([0, ymax])\n",
    "axs[3].plot(stc.times*1000, np.mean(np.array(stcs_rh_4),axis=0)[0], color='#1f77b4')\n",
    "axs[3].plot(stc.times*1000, np.mean(np.array(stcs_lh_4),axis=0)[0], color='#ff7f0e')\n",
    "axs[3].grid(axis='x'); axs[3].set_ylim([0, ymax])\n",
    "axs[4].plot(stc.times*1000, np.mean(np.array(stcs_rh_5),axis=0)[0], color='#1f77b4')\n",
    "axs[4].plot(stc.times*1000, np.mean(np.array(stcs_lh_5),axis=0)[0], color='#ff7f0e')\n",
    "axs[4].grid(axis='x'); axs[4].set_ylim([0, ymax])\n",
    "axs[5].plot(stc.times*1000, np.mean(np.array(stcs_rh_6),axis=0)[0], color='#1f77b4')\n",
    "axs[5].plot(stc.times*1000, np.mean(np.array(stcs_lh_6),axis=0)[0], color='#ff7f0e')\n",
    "axs[5].grid(axis='x'); axs[5].set_ylim([0, ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the evoked response is significantly different between two conditions across subjects\n",
    "event_1 = 'PO70_95'\n",
    "event_2 = 'GP70_i240'\n",
    "\n",
    "# iterate over files, reading files and check\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_ev_1 = []\n",
    "stc_files_list_ev_2 = []\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\"): # or -rh\n",
    "        if event_1 in f:\n",
    "            stc_files_list_ev_1.append(f)\n",
    "        if event_2 in f:\n",
    "            stc_files_list_ev_2.append(f)\n",
    "\n",
    "if len(stc_files_list_ev_1) == len(stc_files_list_ev_2):\n",
    "    n_subjects = len(stc_files_list_ev_2)\n",
    "else:\n",
    "    raise ValueError('number of subjects for two events are not same')\n",
    "\n",
    "data_ev_1 = []\n",
    "data_ev_2 = []\n",
    "for stc_file_ev_1, stc_file_ev_2 in zip(stc_files_list_ev_1, stc_files_list_ev_2):\n",
    "    stc_ev1 = mne.read_source_estimate(fname=stc_file_ev_1, subject='fsaverage')\n",
    "    stc_ev2 = mne.read_source_estimate(fname=stc_file_ev_2, subject='fsaverage')\n",
    "    data_ev_1.append(stc_ev1.data)\n",
    "    data_ev_2.append(stc_ev2.data)\n",
    "\n",
    "# Creating the big matrix\n",
    "n_vertices, n_times = stc_ev1.data.shape\n",
    "tmin = stc_ev1.tmin\n",
    "tstep = stc_ev1.tstep * 1000 \n",
    "np.random.seed(0)\n",
    "X = np.zeros((n_vertices, n_times, n_subjects, 2))\n",
    "\n",
    "for condition_idx, condition in enumerate(data_ev_1):\n",
    "    X[:, :, condition_idx, 0] += condition\n",
    "for condition_idx, condition in enumerate(data_ev_2):\n",
    "    X[:, :, condition_idx, 1] += condition\n",
    "\n",
    "X = np.abs(X)  \n",
    "X = X[:, :, :, 0] - X[:, :, :, 1] \n",
    "X = np.transpose(X, [2, 1, 0]) # observations (subjects) × time × space\n",
    "\n",
    "# compute adjacency matrix\n",
    "src_fname = '/Users/payamsadeghishabestari/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif'\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "fsave_vertices = [s[\"vertno\"] for s in src]\n",
    "adjacency = mne.spatial_src_adjacency(src, verbose=False)\n",
    "\n",
    "# cluster forming threshold based on a p-value (two-tailed test)\n",
    "p_threshold = 0.001\n",
    "df = n_subjects - 1  \n",
    "n_permutations = 1024\n",
    "t_threshold = stats.distributions.t.ppf(1 - p_threshold / 2, df=df)\n",
    "T_obs, clusters, cluster_p_values, H0 = clu = spatio_temporal_cluster_1samp_test(\n",
    "                                                X, threshold=t_threshold,\n",
    "                                                n_permutations=n_permutations, adjacency=adjacency,\n",
    "                                                n_jobs=-1, verbose=True)\n",
    "\n",
    "# Select the clusters that are statistically significant at p < 0.05\n",
    "good_clusters_idx = np.where(cluster_p_values < 0.05)[0]\n",
    "good_clusters = [clusters[idx] for idx in good_clusters_idx]\n",
    "\n",
    "# Visualize the clusters (blue blobs are for event 1 < event 2, red for event 1 > event 2)\n",
    "colormap = \"auto\"\n",
    "clim = dict(kind=\"value\", lims=[0, 1, 40])\n",
    "stc_all_cluster_vis = summarize_clusters_stc(clu, tstep=tstep, subject=\"fsaverage\", vertices=fsave_vertices)\n",
    "brain = stc_all_cluster_vis.plot(views=\"lat\", hemi=\"split\", size=(800, 400), subject='fsaverage',\n",
    "                    subjects_dir=None, background=\"w\", colorbar=True, clim=clim, colormap=colormap, \n",
    "                    time_label=\"temporal extent (ms)\", time_viewer=True, show_traces=True, smoothing_steps=4)\n",
    "\n",
    "# ***** The first time point in this SourceEstimate object is the summation of all the clusters.\n",
    "#       Subsequent time points contain each individual cluster.\n",
    "#       The magnitude of the activity corresponds to the duration spanned by the cluster *****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from Source to Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking only one example (also checking different modes)\n",
    "stc_fname = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/539_PO60_90-lh.stc-lh.stc'\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "bl_idx = -1\n",
    "# extracting time course from source_estimate object in label index 0 (bankssts-lh)\n",
    "stc = mne.read_source_estimate(fname=stc_fname, subject='fsaverage')\n",
    "stc_v_label = stc.in_label(brain_labels[bl_idx])\n",
    "modes = (\"mean\", \"mean_flip\", \"pca_flip\", \"max\")\n",
    "tcs = dict()\n",
    "for mode in modes:\n",
    "    tcs[mode] = stc.extract_label_time_course(brain_labels[bl_idx], src, mode=mode, verbose=False)\n",
    "\n",
    "# plotting\n",
    "fig, ax = plt.subplots(1,1, figsize=(11,5))\n",
    "t = 1e3 * stc.times\n",
    "ax.plot(t, stc_v_label.data.T, \"k\", linewidth=0.5, alpha=0.2)\n",
    "for mode, tc in tcs.items():\n",
    "    ax.plot(t, tc[0], linewidth=3, label=str(mode))\n",
    "\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set(xlabel=\"Time (ms)\", ylabel=\"Source amplitude\",\n",
    "    title=\"Activations in Label %r\" % (brain_labels[bl_idx].name))\n",
    "mne.viz.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all sibjects\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list = []\n",
    "event = 'GO_70'\n",
    "for filename in sorted(os.listdir(directory)): \n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f: # or -rh\n",
    "            stc_files_list.append(f)\n",
    "\n",
    "# initializing\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "rh_labels = [bl.name for bl in brain_labels if '-rh' in bl.name]\n",
    "lh_labels = [bl.name for bl in brain_labels if '-lh' in bl.name]\n",
    "dict_max_rh_label = {} \n",
    "dict_max_lh_label = {} \n",
    "\n",
    "for stc_fname in tqdm(stc_files_list):\n",
    "    subject_id = stc_fname[58:61]\n",
    "    stc = mne.read_source_estimate(fname=stc_fname, subject='fsaverage')\n",
    "    \n",
    "    tcs_max_rh = []\n",
    "    tcs_max_lh = []\n",
    "    for bl_idx in range(len(brain_labels)):\n",
    "        if '-rh' in brain_labels[bl_idx].name:\n",
    "            tcs_max_rh.append(stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False).max())\n",
    "        if '-lh' in brain_labels[bl_idx].name:\n",
    "            tcs_max_lh.append(stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False).max())\n",
    "\n",
    "    bl_rh_max = rh_labels[np.argmax(np.array(tcs_max_rh))]\n",
    "    bl_lh_max = lh_labels[np.argmax(np.array(tcs_max_lh))]\n",
    "\n",
    "    dict_max_rh_label[subject_id] = bl_rh_max\n",
    "    dict_max_lh_label[subject_id] = bl_lh_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making big dataframe with all information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making big dataframe for transverstemporal rh/lh\n",
    "my_dict = {'subject ID': [], 'Stimulus': [], 'Hemisphere': [], 'latency': [],\n",
    "        'PSNR': [], 'peak value (30ms)': [], 'peak value (100ms)': [], 'area value (30ms)': [],\n",
    "        'area value (100ms)': [], 'amplitude inhibition (30ms)': [], 'area inhibition (30ms)': [],\n",
    "        'amplitude inhibition (100ms)': [], 'area inhibition (100ms)': [], 'EOG peak': [],\n",
    "        'EOG ptp': [], 'EOG area (30ms)': [], 'EOG area (100ms)': [], 'EOG peak latency': []} \n",
    "\n",
    "# events = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95',\n",
    "#         'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95',\n",
    "#         'GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240',\n",
    "#         'GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240',\n",
    "#         'GO_60', 'GO_70']\n",
    "\n",
    "events = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "        'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "        'GPP_08', 'GPG_08', 'PO_08', 'GO_08',\n",
    "        'GPP_30', 'GPG_30', 'PO_30', 'GO_30',\n",
    "        'GPP_33', 'GPG_33', 'PO_33', 'GO_33',\n",
    "        'GPP_38', 'GPG_38', 'PO_38', 'GO_38',\n",
    "        'GPP_80', 'GPG_80', 'PO_80', 'GO_80',\n",
    "        'GPP_83', 'GPG_83', 'PO_83', 'GO_83',\n",
    "        'GPP_88', 'GPG_88', 'PO_88', 'GO_88']\n",
    "\n",
    "# events = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "#         'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "#         'GPP_08', 'GPG_08', 'PO_08', 'GO_08']\n",
    "\n",
    "# subjects = ['539', '697', '750', '756', '832', '835', '836', '838', '839',\n",
    "#             '840', '841', '842', '844', '845', '847', '849', '850', '852', '853',\n",
    "#             '856', '857', '858', '859', '861', '862', '863'] # should I exclude 3 subjects?\n",
    "\n",
    "subjects = ['916', '979', '980', '981', '982', '983', '984', '986', '988']\n",
    "\n",
    "# subjects = ['1004', '1006', '1008', '1009', '1017', '1021', '1025', '1031',\n",
    "#             '1032', '1033', '1034', '1035', '1037', '1038', '1044', '1045', '1047', '1048']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "directory_stcs = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg2_morphed'\n",
    "directory_eps = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg2/epochs_bads_dropped'\n",
    "\n",
    "# looping over all files\n",
    "for subject in tqdm(subjects):\n",
    "    for stim in events:\n",
    "        for hemi in ['lh', 'rh']:\n",
    "            for filename in sorted(os.listdir(directory_stcs)): \n",
    "                f = os.path.join(directory_stcs, filename)\n",
    "                if os.path.isfile(f) and f.endswith(f\"-{hemi}.stc\") and stim in f and subject in f:\n",
    "                    \n",
    "                    # reading source estimate file\n",
    "                    stc_fname = f\n",
    "                    stc = mne.read_source_estimate(fname=stc_fname, subject='fsaverage')\n",
    "                    \n",
    "                    # reading epoch file for eog response\n",
    "                    for filename in sorted(os.listdir(directory_eps)): \n",
    "                        f = os.path.join(directory_eps, filename)\n",
    "                        if os.path.isfile(f) and f.endswith('-epo.fif') and subject in f:\n",
    "                            ep_fname = f\n",
    "                            ep = mne.read_epochs(fname=ep_fname, preload=True, verbose=False)\n",
    "                    \n",
    "                    eog_peak_value = abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[75:].min() * 1e6) # only positive\n",
    "                    argmin = np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[75:].argmin() + 75\n",
    "                    eog_peak_time = np.linspace(-300, 300, 151)[argmin]\n",
    "                    (t1, t2) = (argmin - 5, argmin + 4)\n",
    "                    (t3, t4) = (argmin - 14, argmin + 13)\n",
    "                    my_dict['EOG peak'].append(eog_peak_value)\n",
    "                    my_dict['EOG ptp'].append(np.ptp(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[75:]) * 1e6)\n",
    "                    my_dict['EOG area (30ms)'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[t1:t2].sum() * 1e6))\n",
    "                    my_dict['EOG area (100ms)'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[t3:t4].sum() * 1e6))\n",
    "                    my_dict['EOG peak latency'].append(eog_peak_time)\n",
    "                    \n",
    "                    # localizing the brain label\n",
    "                    if hemi == 'rh':\n",
    "                        bl_idx = -1 # transversetemporal-rh\n",
    "                    if hemi == 'lh':\n",
    "                        bl_idx = -2 # transversetemporal-lh\n",
    "\n",
    "                    # computing some params in stc object   \n",
    "                    tcs_noise_avg = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,:76].mean()\n",
    "                    tcs_peak_100ms = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].max()\n",
    "                    tcs_peak_30ms = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].max()\n",
    "                    tcs_area_100ms = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].sum()\n",
    "                    tcs_area_30ms = stc.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].sum()\n",
    "                    \n",
    "                    # computing inhibition indexes for tinmeg1\n",
    "                    # if '60' in stim and '70' not in stim:\n",
    "                    #     stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO60_90-lh.stc-lh.stc'\n",
    "                    #     stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                    #     tcs_peak_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                    #                                                             src, mode='mean', verbose=False)[:,96:105].max()\n",
    "                    #     tcs_area_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].sum()\n",
    "                    #     tcs_peak_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                    #                                                             src, mode='mean', verbose=False)[:,87:114].max()\n",
    "                    #     tcs_area_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].sum()\n",
    "\n",
    "                    # if '70' in stim:\n",
    "                    #     stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO70_90-lh.stc-lh.stc'\n",
    "                    #     stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                    #     tcs_peak_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                    #                                                             src, mode='mean', verbose=False)[:,96:105].max()\n",
    "                    #     tcs_area_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].sum()\n",
    "                    #     tcs_peak_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                    #                                                             src, mode='mean', verbose=False)[:,87:114].max()\n",
    "                    #     tcs_area_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].sum()\n",
    "            \n",
    "                    # computing inhibition indexes for tinmeg2\n",
    "                    stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg2_morphed/{subject}_PO_{stim[-2:]}-lh.stc-lh.stc'\n",
    "                    stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                    tcs_peak_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                                                                            src, mode='mean', verbose=False)[:,96:105].max()\n",
    "                    tcs_area_30ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,96:105].sum()\n",
    "                    tcs_peak_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx],\n",
    "                                                                            src, mode='mean', verbose=False)[:,87:114].max()\n",
    "                    tcs_area_100ms_stn = stc_stn.extract_label_time_course(brain_labels[bl_idx], src, mode='mean', verbose=False)[:,87:114].sum()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    my_dict['amplitude inhibition (30ms)'].append((1 - (tcs_peak_30ms / tcs_peak_30ms_stn)) * 100)\n",
    "                    my_dict['area inhibition (30ms)'].append((1 - (tcs_area_30ms / tcs_area_30ms_stn)) * 100)\n",
    "                    my_dict['amplitude inhibition (100ms)'].append((1 - (tcs_peak_100ms / tcs_peak_100ms_stn)) * 100)\n",
    "                    my_dict['area inhibition (100ms)'].append((1 - (tcs_area_100ms / tcs_area_100ms_stn)) * 100)\n",
    "\n",
    "                    # putting in the dictionary\n",
    "                    my_dict['subject ID'].append(subject)\n",
    "                    my_dict['Stimulus'].append(stim)\n",
    "                    my_dict['Hemisphere'].append(hemi)\n",
    "                    my_dict['latency'].append(stc.extract_label_time_course(brain_labels[bl_idx], src,\n",
    "                                                                            mode='mean', verbose=False)[:,87:114].argmax() + 87) \n",
    "                    my_dict['PSNR'].append(20 * np.log10(tcs_peak_30ms / tcs_noise_avg))\n",
    "                    my_dict['peak value (30ms)'].append(tcs_peak_30ms)\n",
    "                    my_dict['peak value (100ms)'].append(tcs_peak_100ms)\n",
    "                    my_dict['area value (30ms)'].append(tcs_area_30ms)\n",
    "                    my_dict['area value (100ms)'].append(tcs_area_100ms)\n",
    "                    \n",
    "df = pd.DataFrame(my_dict)\n",
    "# save it\n",
    "df.to_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg2_transverstemporal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making big dataframe total left and right hemispheres\n",
    "my_dict = {'subject ID': [], 'Stimulus': [], 'Hemisphere': [], 'latency': [],\n",
    "        'PSNR': [], 'peak value (30ms)': [], 'peak value (100ms)': [], 'area value (30ms)': [],\n",
    "        'area value (100ms)': [], 'amplitude inhibition (30ms)': [], 'area inhibition (30ms)': [],\n",
    "        'amplitude inhibition (100ms)': [], 'area inhibition (100ms)': [], 'EOG peak': [],\n",
    "        'EOG ptp': [], 'EOG area (30ms)': [], 'EOG area (100ms)': []}\n",
    "\n",
    "events = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95',\n",
    "        'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95',\n",
    "        'GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240',\n",
    "        'GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240',\n",
    "        'GO_60', 'GO_70']\n",
    "\n",
    "subjects = ['539', '697', '750', '756', '832', '835', '836', '838', '839',\n",
    "            '840', '841', '842', '844', '845', '847', '849', '850', '852', '853',\n",
    "            '856', '857', '858', '859', '861', '862', '863'] \n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "directory_stcs = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "directory_eps = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg1'\n",
    "\n",
    "# looping over all files\n",
    "for subject in tqdm(subjects):\n",
    "    for stim in events:\n",
    "        for hemi in ['lh', 'rh']:\n",
    "            for filename in sorted(os.listdir(directory_stcs)): \n",
    "                f = os.path.join(directory_stcs, filename)\n",
    "                if os.path.isfile(f) and f.endswith(f\"-{hemi}.stc\") and stim in f and subject in f:\n",
    "                    \n",
    "                    # reading source estimate file\n",
    "                    stc_fname = f\n",
    "                    stc = mne.read_source_estimate(fname=stc_fname, subject='fsaverage')\n",
    "                    \n",
    "                    # reading epoch file for eog response\n",
    "                    for filename in sorted(os.listdir(directory_eps)): \n",
    "                        f = os.path.join(directory_eps, filename)\n",
    "                        if os.path.isfile(f) and f.endswith('-epo.fif') and subject in f:\n",
    "                            ep_fname = f\n",
    "                            ep = mne.read_epochs(fname=ep_fname, preload=True, verbose=False)\n",
    "                    \n",
    "                    my_dict['EOG peak'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0).min() * 1e6))\n",
    "                    my_dict['EOG ptp'].append(np.ptp(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)) * 1e6)\n",
    "                    my_dict['EOG area (30ms)'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[96:105].sum() * 1e6))\n",
    "                    my_dict['EOG area (100ms)'].append(abs(np.squeeze(ep[stim].get_data(picks=['EOG002'])).mean(axis=0)[87:114].sum() * 1e6))\n",
    "                    \n",
    "                    # localizing the brain label\n",
    "                    if hemi == 'rh':\n",
    "                        tcs_noise_avg = stc.rh_data.mean(axis=0)[:76].mean()\n",
    "                        tcs_peak_100ms = stc.rh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_peak_30ms = stc.rh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_100ms = stc.rh_data.mean(axis=0)[87:114].sum()\n",
    "                        tcs_area_30ms = stc.rh_data.mean(axis=0)[96:105].sum()\n",
    "                        check = 1\n",
    "\n",
    "                    if hemi == 'lh':\n",
    "                        tcs_noise_avg = stc.lh_data.mean(axis=0)[:76].mean()\n",
    "                        tcs_peak_100ms = stc.lh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_peak_30ms = stc.lh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_100ms = stc.lh_data.mean(axis=0)[87:114].sum()\n",
    "                        tcs_area_30ms = stc.lh_data.mean(axis=0)[96:105].sum()\n",
    "                        check = 2\n",
    "\n",
    "                    # computing inhibition indexes\n",
    "                    if '60' in stim and '70' not in stim and check==1:\n",
    "                        stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO60_90-lh.stc-lh.stc'\n",
    "                        stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                        tcs_peak_30ms_stn = stc_stn.rh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_30ms_stn = stc_stn.rh_data.mean(axis=0)[96:105].sum()\n",
    "                        tcs_peak_100ms_stn = stc_stn.rh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_area_100ms_stn = stc_stn.rh_data.mean(axis=0)[87:114].sum()\n",
    "\n",
    "                    if '60' in stim and '70' not in stim and check==2:\n",
    "                        stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO60_90-lh.stc-lh.stc'\n",
    "                        stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                        tcs_peak_30ms_stn = stc_stn.lh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_30ms_stn = stc_stn.lh_data.mean(axis=0)[96:105].sum()\n",
    "                        tcs_peak_100ms_stn = stc_stn.lh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_area_100ms_stn = stc_stn.lh_data.mean(axis=0)[87:114].sum()\n",
    "\n",
    "                    if '70' in stim and check==1:\n",
    "                        stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO70_90-lh.stc-lh.stc'\n",
    "                        stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                        tcs_peak_30ms_stn = stc_stn.rh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_30ms_stn = stc_stn.rh_data.mean(axis=0)[96:105].sum()\n",
    "                        tcs_peak_100ms_stn = stc_stn.rh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_area_100ms_stn = stc_stn.rh_data.mean(axis=0)[87:114].sum()\n",
    "\n",
    "                    if '70' in stim and check==2:\n",
    "                        stc_fname_stn = f'/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed/{subject}_PO70_90-lh.stc-lh.stc'\n",
    "                        stc_stn = mne.read_source_estimate(fname=stc_fname_stn, subject='fsaverage')\n",
    "                        tcs_peak_30ms_stn = stc_stn.lh_data.mean(axis=0)[96:105].max()\n",
    "                        tcs_area_30ms_stn = stc_stn.lh_data.mean(axis=0)[96:105].sum()\n",
    "                        tcs_peak_100ms_stn = stc_stn.lh_data.mean(axis=0)[87:114].max()\n",
    "                        tcs_area_100ms_stn = stc_stn.lh_data.mean(axis=0)[87:114].sum()\n",
    "            \n",
    "                    \n",
    "                    my_dict['amplitude inhibition (30ms)'].append((1 - (tcs_peak_30ms / tcs_peak_30ms_stn)) * 100)\n",
    "                    my_dict['area inhibition (30ms)'].append((1 - (tcs_area_30ms / tcs_area_30ms_stn)) * 100)\n",
    "                    my_dict['amplitude inhibition (100ms)'].append((1 - (tcs_peak_100ms / tcs_peak_100ms_stn)) * 100)\n",
    "                    my_dict['area inhibition (100ms)'].append((1 - (tcs_area_100ms / tcs_area_100ms_stn)) * 100)\n",
    "\n",
    "                    if check==1:\n",
    "                        my_dict['latency'].append(stc.rh_data.mean(axis=0)[87:114].argmax() + 87)\n",
    "                    if check==2:\n",
    "                        my_dict['latency'].append(stc.lh_data.mean(axis=0)[87:114].argmax() + 87)     \n",
    "                    \n",
    "                    # putting in the dictionary\n",
    "                    my_dict['subject ID'].append(subject)\n",
    "                    my_dict['Stimulus'].append(stim)\n",
    "                    my_dict['Hemisphere'].append(hemi)\n",
    "                    my_dict['PSNR'].append(20 * np.log10(tcs_peak_30ms / tcs_noise_avg))\n",
    "                    my_dict['peak value (30ms)'].append(tcs_peak_30ms)\n",
    "                    my_dict['peak value (100ms)'].append(tcs_peak_100ms)\n",
    "                    my_dict['area value (30ms)'].append(tcs_area_30ms)\n",
    "                    my_dict['area value (100ms)'].append(tcs_area_100ms)\n",
    "                    \n",
    "df = pd.DataFrame(my_dict)\n",
    "# save it\n",
    "df.to_csv('/Users/payamsadeghishabestari/KI_MEG/dataframe_tinmeg1_hemisphere.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting tinmeg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe and remove three subjects\n",
    "df = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv') \n",
    "mask = df['subject ID'].isin([697, 750, 853, 841])\n",
    "df = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont run this part (it is alread applied)\n",
    "# adding an extra column to the dataframe (eog inhibition)\n",
    "subject_ids = np.array(df['subject ID']).astype(str)\n",
    "stimuli = np.array(df['Stimulus']).astype(str)\n",
    "eog_peaks = np.array(df['EOG peak'])\n",
    "eog_ptps = np.array(df['EOG ptp'])\n",
    "eog_areas = np.array(df['EOG area (30ms)'])\n",
    "\n",
    "eog_amp_inhibits = []\n",
    "eog_ptp_inhibits = []\n",
    "eog_area_inhibits = []\n",
    "for idx, (eog_peak, eog_ptp, eog_area) in enumerate(zip(eog_peaks, eog_ptps, eog_areas)):\n",
    "    sub_id = subject_ids[idx]\n",
    "    stimulus = stimuli[idx]\n",
    "    array1 = np.where(subject_ids == sub_id)[0]\n",
    "    \n",
    "    if '60' in stimulus:\n",
    "        array2 = np.where(stimuli == 'PO60_90')[0]\n",
    "    if '70' in stimulus:\n",
    "        array2 = np.where(stimuli == 'PO70_90')[0]\n",
    "    \n",
    "    set1 = set(array1)\n",
    "    set2 = set(array2)\n",
    "    common_idx = list(set1.intersection(set2))[0]\n",
    "    eog_peak_stn = eog_peaks[common_idx]\n",
    "    eog_ptp_stn = eog_ptps[common_idx]\n",
    "    eog_area_stn = eog_areas[common_idx]\n",
    "    \n",
    "    eog_amp_inhibit = (1 - eog_peak / eog_peak_stn) * 100\n",
    "    eog_ptp_inhibit = (1 - eog_ptp / eog_ptp_stn) * 100\n",
    "    eog_area_inhibit = (1 - eog_area / eog_area_stn) * 100\n",
    "    \n",
    "    eog_amp_inhibits.append(eog_amp_inhibit)\n",
    "    eog_ptp_inhibits.append(eog_ptp_inhibit)\n",
    "    eog_area_inhibits.append(eog_area_inhibit)\n",
    "\n",
    "df['EOG peak inhibition'] = eog_amp_inhibits\n",
    "df['EOG ptp inhibition'] = eog_ptp_inhibits\n",
    "df['EOG area inhibition'] = eog_area_inhibits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Figure 1 a\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "color='grey'\n",
    "order_1 = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "order_2 = ['PO60_70', 'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95']\n",
    "df1 = df[df['Hemisphere']=='rh']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='EOG area (30ms)', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0, color=color, order=order_2, ax=ax)\n",
    "color='#9467bd' # #ff7f0e\n",
    "sns.stripplot(data=df1, x='Stimulus', y='EOG area (30ms)',\n",
    "            dodge=False, size=3, color=color, order=order_2, ax=ax)\n",
    "ax.set_ylim([0, 1100])\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "\n",
    "# plotting Figure 1 b\n",
    "order_1 = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "order_2 = ['PO60_70', 'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95']\n",
    "mask = df['Stimulus'].isin(order_1)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,4))\n",
    "palette_color = ['#1f77b4', '#d62728'] \n",
    "sns.boxplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, order=order_1, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_1, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper left')\n",
    "\n",
    "# plotting Figure 1 c\n",
    "fig, ax = plt.subplots(figsize=(11, 4))\n",
    "colors = sns.color_palette('Set1')[1:5]\n",
    "# colors = np.array(sns.color_palette('Set1'))[[1, 2, 6, 7, 3, 0, 8],:]\n",
    "data = [19, 1, 2, 1]\n",
    "# data = [11, 4, 2, 2, 2, 1, 1]\n",
    "ingredients = ['transverstemporal-rh', 'bankssts-rh', 'entorhinal-rh', 'temporalpole-rh']\n",
    "# ingredients = ['transverstemporal-lh', 'bankssts-lh', 'rostralanteriorcingulate-lh', 'paracentral-lh',\n",
    "#                'entorhinal-lh', 'posteriorcingulate-lh', 'lateralorbitofrontal-lh']\n",
    "def func(pct, allvals):\n",
    "    absolute = int(np.round(pct/100.*np.sum(allvals)))\n",
    "    return f\"{pct:.1f}%\"\n",
    "wedges, autotexts = ax.pie(data, textprops=dict(color=\"w\"), colors=colors)\n",
    "legend_names = [f'{name} ({round(number/23*100, 1)}%)' for name, number in zip(ingredients, data)]\n",
    "ax.legend(wedges, legend_names, loc=\"center left\",\n",
    "            bbox_to_anchor=(1, 0, 0.5, 1), frameon=False, fontsize=12)\n",
    "\n",
    "# figure 1 d (needs to run previous parts)\n",
    "grand_ev_dict['PO60_90'].plot_topomap(times=0.1, time_unit='ms', contours=6)\n",
    "\n",
    "# figure 1 e\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_rh = {'PO60_70': [], 'PO60_75': [], 'PO60_80': [],\n",
    "                'PO60_85': [], 'PO60_90': [], 'PO60_95': []}\n",
    "stc_files_list_lh = {'PO60_70': [], 'PO60_75': [], 'PO60_80': [],\n",
    "                'PO60_85': [], 'PO60_90': [], 'PO60_95': []}\n",
    "events = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "\n",
    "for event in events:\n",
    "    for filename in sorted(os.listdir(directory)): \n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f: # or -rh\n",
    "                stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "                rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "                lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "                stc_files_list_rh[event].append(rh_data)\n",
    "                stc_files_list_lh[event].append(lh_data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,3))\n",
    "lw = 0.5\n",
    "colors = ['#1f77b4', '#d62728']\n",
    "for event in events[:-1]:\n",
    "    data = np.squeeze(np.array(stc_files_list_lh[event])).mean(axis=0)\n",
    "    ax.plot(np.linspace(-300, 300, 151), data.T, label=event, linewidth=lw, color=colors[0])\n",
    "    lw += 0.4\n",
    "for event in events[-1:]:\n",
    "    data = np.squeeze(np.array(stc_files_list_lh[event])).mean(axis=0)\n",
    "    ax.plot(np.linspace(-300, 300, 151), data.T, label=event, linewidth=lw, color='k')\n",
    "    lw += 0.4\n",
    "\n",
    "ax.axvspan(50, 150, alpha=0.5, color='lightgrey')\n",
    "ax.vlines(0, 0.5, 6, colors='black',linestyles='--')\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, 0.5, 6, colors='black',linestyles=':', linewidth=0.5)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='upper right', ncols=6, fontsize=9, frameon=False, bbox_to_anchor=(0.6, 0.6, 0.6, 0.6))\n",
    "ax.set_xlim([-310, 310])\n",
    "ax.set_ylim([0, 6])\n",
    "\n",
    "# extra plot\n",
    "Brain = mne.viz.get_brain_class()\n",
    "clr = 0.85\n",
    "brain_kwargs = dict(alpha=1, background=\"white\", cortex=[(clr, clr, clr), (clr, clr, clr)], size=(800, 600), views='lateral')\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 69 labels\n",
    "brain = Brain(\"fsaverage\", hemi=\"lh\", surf=\"pial_semi_inflated\", **brain_kwargs)\n",
    "brain.add_label(brain_labels[-2], hemi=\"lh\", color=\"#d62728\", borders=False, alpha=0.9)\n",
    "brain.show_view(roll=20, azimuth=30, elevation=80, distance=400)\n",
    "\n",
    "#### figure 1 f\n",
    "fig, axs = plt.subplots(1, 1, figsize=(6, 3))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "color = '#ff7f0e'\n",
    "lw = 0.5\n",
    "for stim in stims[:-1]:\n",
    "    axs.plot(time_array, abs(grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6),\n",
    "            linewidth=lw, label=stim, color=color)\n",
    "    lw += 0.4\n",
    "for stim in stims[-1:]:\n",
    "    axs.plot(time_array, abs(grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6),\n",
    "            linewidth=lw, label=stim, color='k')\n",
    "    \n",
    "axs.axvspan(50, 180, alpha=0.4, color='lightgrey')\n",
    "axs.legend(fontsize=9, frameon=False, bbox_to_anchor=(0.5, 0.1, 0.6, 0.6))\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    axs.vlines(i, -10, 60, colors='black',linestyles=':', linewidth=0.5)\n",
    "axs.vlines(0, -10, 60, colors='black',linestyles='--')\n",
    "axs.set_ylabel(f'EOG amplitude at 70 dB (µv)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_ylim([-10, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## figure 4 a (extra)\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_rh = {'PO60_90': [], 'GP60_i240': []}\n",
    "stc_files_list_lh = {'PO60_90': [], 'GP60_i240': []}\n",
    "events = ['PO60_90', 'GP60_i240']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "\n",
    "for event in events:\n",
    "    for filename in sorted(os.listdir(directory)): \n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f: # or -rh\n",
    "                stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "                rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "                lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "                stc_files_list_rh[event].append(rh_data)\n",
    "                stc_files_list_lh[event].append(lh_data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,3))\n",
    "lw = None\n",
    "# colors = ['#d62728', '#1f77b4']\n",
    "colors = ['#1f77b4', '#d62728']\n",
    "\n",
    "data = np.squeeze(np.array(stc_files_list_lh[events[0]])).mean(axis=0)\n",
    "data_std = stats.sem(a=np.squeeze(np.array(stc_files_list_lh[event])), axis=0)\n",
    "ax.plot(np.linspace(-300, 300, 151), data.T, label=events[0], linewidth=lw, color=colors[0])\n",
    "ax.fill_between(np.linspace(-300, 300, 151), data.T - data_std.T,\n",
    "                    data.T + data_std.T, color=colors[0], alpha=0.2, edgecolor=\"none\")\n",
    "\n",
    "data = np.squeeze(np.array(stc_files_list_lh[events[1]])).mean(axis=0)\n",
    "data_std = stats.sem(a=np.squeeze(np.array(stc_files_list_lh[event])), axis=0)\n",
    "ax.plot(np.linspace(-300, 300, 151), data.T, label=events[1], linewidth=lw, color=colors[0], linestyle='--')\n",
    "ax.fill_between(np.linspace(-300, 300, 151), data.T - data_std.T,\n",
    "                    data.T + data_std.T, color=colors[0], alpha=0.2, edgecolor=\"none\")\n",
    "\n",
    "data = np.squeeze(np.array(stc_files_list_rh[events[0]])).mean(axis=0)\n",
    "data_std = stats.sem(a=np.squeeze(np.array(stc_files_list_rh[event])), axis=0)\n",
    "ax.plot(np.linspace(-300, 300, 151), data.T, label=events[0], linewidth=lw, color=colors[1])\n",
    "ax.fill_between(np.linspace(-300, 300, 151), data.T - data_std.T,\n",
    "                    data.T + data_std.T, color=colors[1], alpha=0.2, edgecolor=\"none\")\n",
    "\n",
    "data = np.squeeze(np.array(stc_files_list_rh[events[1]])).mean(axis=0)\n",
    "data_std = stats.sem(a=np.squeeze(np.array(stc_files_list_rh[event])), axis=0)\n",
    "ax.plot(np.linspace(-300, 300, 151), data.T, label=events[1], linewidth=lw, color=colors[1], linestyle='--')\n",
    "ax.fill_between(np.linspace(-300, 300, 151), data.T - data_std.T,\n",
    "                    data.T + data_std.T, color=colors[1], alpha=0.2, edgecolor=\"none\")\n",
    "\n",
    "\n",
    "ax.axvspan(50, 150, alpha=0.5, color='lightgrey')\n",
    "ax.vlines(0, 0.5, 6, colors='black',linestyles='--')\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, 0.5, 6, colors='black',linestyles=':', linewidth=0.5)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='upper right', ncols=6, fontsize=9, frameon=False, bbox_to_anchor=(0.6, 0.6, 0.6, 0.6))\n",
    "ax.set_xlim([-310, 310])\n",
    "ax.set_ylim([0, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(6, 3))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['PO70_90', 'GP70_i240']\n",
    "color = '#ff7f0e'\n",
    "lw = None\n",
    "\n",
    "eog_evs_po = []\n",
    "for ev in np.array(evs)[:,4]: #PO70_90\n",
    "    eog_evs_po.append(abs(ev.get_data(picks='EOG002')[0] * 1e6))\n",
    "\n",
    "eog_evs_gp = []\n",
    "for ev in np.array(evs)[:,14]: #GP70_i240\n",
    "    eog_evs_gp.append(abs(ev.get_data(picks='EOG002')[0] * 1e6))\n",
    "\n",
    "data = abs(np.array(eog_evs_po)).mean(axis=0)\n",
    "data_std = stats.sem(a=abs(np.array(eog_evs_gp)), axis=0)\n",
    "axs.plot(time_array, data, linewidth=lw, label=stim, color=color)\n",
    "axs.fill_between(np.linspace(-300, 300, 151), data.T - data_std.T,\n",
    "                    data.T + data_std.T, color=color, alpha=0.2, edgecolor=\"none\")\n",
    "\n",
    "data = abs(np.array(eog_evs_gp)).mean(axis=0)\n",
    "data_std = stats.sem(a=abs(np.array(eog_evs_gp)), axis=0)\n",
    "axs.plot(time_array, data, linewidth=lw, label=stim, color=color, linestyle='--')\n",
    "axs.fill_between(np.linspace(-300, 300, 151), data.T - data_std.T,\n",
    "                    data.T + data_std.T, color=color, alpha=0.2, edgecolor=\"none\")\n",
    "    \n",
    "axs.axvspan(50, 180, alpha=0.4, color='lightgrey')\n",
    "axs.legend(fontsize=9, frameon=False, bbox_to_anchor=(1.5, 0.1, 0.6, 0.6))\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    axs.vlines(i, -10, 60, colors='black',linestyles=':', linewidth=0.5)\n",
    "axs.vlines(0, -10, 60, colors='black',linestyles='--')\n",
    "axs.set_ylabel(f'EOG amplitude at 70 dB (µv)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_ylim([-10, 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Figure 2 a\n",
    "data1 = grand_ev_dict['GO_60'].get_data(picks='EOG002')[0] * 1e6\n",
    "data2 = grand_ev_dict['GO_70'].get_data(picks='EOG002')[0] * 1e6\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "ax.plot(np.linspace(-300, 300, 151), abs(data1), label='GO_60', color='#ff7f0e', linewidth=2)\n",
    "ax.plot(np.linspace(-300, 300, 151), abs(data2), label='GO_70', color='#9467bd', linewidth=2)\n",
    "ax.vlines(0, -10, 60, colors='black',linestyles='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='upper left', fontsize=9, frameon=False)\n",
    "ax.set_ylim([-12, 62])\n",
    "ax.set_xlim([-310, 310])\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, -10, 60, colors='black',linestyles=':', linewidth=0.5)\n",
    "\n",
    "# plotting Figure 2 b\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_rh = {'GO_60': [], 'GO_70': []}\n",
    "stc_files_list_lh = {'GO_60': [], 'GO_70': []}\n",
    "events = ['GO_60', 'GO_70']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "\n",
    "for event in events:\n",
    "    for filename in sorted(os.listdir(directory)): \n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f and '697' not in f and '750' not in f and '853' not in f:\n",
    "                stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "                rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "                lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "                stc_files_list_rh[event].append(rh_data)\n",
    "                stc_files_list_lh[event].append(lh_data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "colors = ['#d62728', '#1f77b4'] \n",
    "for event, clr in zip(events, colors):\n",
    "    data = np.squeeze(np.array(stc_files_list_rh[event])).mean(axis=0)\n",
    "    # data_std = np.squeeze(np.array(stc_files_list_rh[event])).std(axis=0)\n",
    "    data_std = stats.sem(a=np.squeeze(np.array(stc_files_list_rh[event])), axis=0)\n",
    "    ax.plot(np.linspace(-300, 300, 151), data.T, label=event, color=clr)\n",
    "    ax.fill_between(np.linspace(-300, 300, 151), data.T - data_std.T,\n",
    "                    data.T + data_std.T, color=clr, alpha=0.1, edgecolor=\"none\")\n",
    "ax.vlines(0, 0.5, 8, colors='black',linestyles='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='upper left', fontsize=9, frameon=False)\n",
    "ax.set_xlim([-310, 310])\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, 0.5, 8, colors='black',linestyles=':', linewidth=0.5)\n",
    "\n",
    "# plotting Figure 2 c\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "# palette_color = 'Set1'\n",
    "palette_color = ['#1f77b4', '#d62728'] \n",
    "order_1 = ['GO_60', 'GO_70']\n",
    "order_2 = ['GO_70']\n",
    "df1 = df[df['Hemisphere']=='rh']\n",
    "sns.boxplot(data=df, x='Stimulus', y='peak value (30ms)', fill=False, linewidth=2, hue='Hemisphere', legend=False,\n",
    "            saturation=0.6, palette=palette_color, order=order_1, gap=0.2, ax=ax)\n",
    "sns.stripplot(data=df, x='Stimulus', y='peak value (30ms)', hue='Hemisphere', legend=False,\n",
    "            dodge=True, size=4, palette=palette_color, order=order_1, ax=ax)\n",
    "ax.set_ylim([0, 13])\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "\n",
    "# plotting Figure 2 e\n",
    "grand_ev_dict['GO_60'].plot_topomap(times=0.1, time_unit='ms', contours=6, vlim=(-240, 240))\n",
    "\n",
    "# plotting Figure 2 d\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fig, ax = plt.subplots(1,1, figsize=(10, 4))\n",
    "colors = np.array(sns.color_palette('Set1'))[[1, 2, 3, 4, 6, 0, 8],:]\n",
    "\n",
    "# data = [17, 1, 1, 1, 2, 1]\n",
    "data = [13, 2, 3, 1, 2, 1, 1]\n",
    "\n",
    "# ingredients = ['transverstemporal-rh', 'bankssts-rh', 'entorhinal-rh', 'temporalpole-rh']\n",
    "ingredients = [brain_labels[67].name, brain_labels[1].name,\n",
    "                brain_labels[9].name, brain_labels[0].name, brain_labels[66].name,\n",
    "                brain_labels[32].name, brain_labels[42].name]\n",
    "def func(pct, allvals):\n",
    "    absolute = int(np.round(pct/100.*np.sum(allvals)))\n",
    "    return f\"{pct:.1f}%\"\n",
    "wedges, autotexts = ax.pie(data, textprops=dict(color=\"w\"), colors=colors)\n",
    "legend_names = [f'{name} ({round(number/23*100, 1)}%)' for name, number in zip(ingredients, data)]\n",
    "ax.legend(wedges, legend_names, loc=\"center left\",\n",
    "        bbox_to_anchor=(1, 0, 0.5, 1), frameon=False, fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Figure 3 a\n",
    "order_1 = ['GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240']\n",
    "order_2 = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "mask = df['Stimulus'].isin(order_1)\n",
    "df1 = df[mask]\n",
    "df2 = df1[df1['Hemisphere']=='rh']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,3))\n",
    "palette_color = ['grey']\n",
    "sns.boxplot(data=df2, x='Stimulus', y='EOG area inhibition', width=0.5, fill=False, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, order=order_1, ax=ax)\n",
    "sns.stripplot(data=df2, x='Stimulus', y='EOG area inhibition',\n",
    "            dodge=False, size=3, palette=palette_color, order=order_1, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "ax.set_ylim([-50, 100])\n",
    "ax.hlines(0, -0.6, 3.6, colors='black',linestyles='--')\n",
    "ax.hlines(50, -0.6, 3.6, colors='grey',linestyles=':')\n",
    "ax.set_yticks([-50, 0, 50, 100])\n",
    "\n",
    "# plotting Figure 3 b\n",
    "order_1 = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "order_2 = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "mask = df['Stimulus'].isin(order_2)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9,3))\n",
    "palette_color = ['#1f77b4', '#d62728']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='area inhibition (30ms)', hue='Hemisphere', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, order=order_2, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='area inhibition (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_2, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "ax.set_ylim([-50, 100])\n",
    "ax.hlines(0, -0.6, 3.6, colors='black',linestyles='--')\n",
    "ax.hlines(50, -0.6, 3.6, colors='grey',linestyles=':')\n",
    "ax.set_yticks([-50, 0, 50, 100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe and remove three subjects\n",
    "df = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg2_transverstemporal.csv') \n",
    "\n",
    "# plotting Figure 4 a \n",
    "order_1 = ['PO_00', 'PO_03', 'PO_08', 'PO_30', 'PO_33', 'PO_38', 'PO_80', 'PO_83', 'PO_88']\n",
    "\n",
    "mask = df['Stimulus'].isin(order_1)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,3))\n",
    "palette_color = ['#d62728', '#d62728', '#d62728',\n",
    "                '#1f77b4', '#1f77b4', '#1f77b4',\n",
    "                '#2ca02c', '#2ca02c', '#2ca02c']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='EOG peak', width=0.3, fill=False, linewidth=2,\n",
    "            saturation=0.55, palette=palette_color, order=order_1, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='EOG peak',\n",
    "            dodge=False, size=3, palette=palette_color, order=order_1, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "# plotting Figure 4 b \n",
    "order_1 = ['PO_00', 'PO_03', 'PO_08', 'PO_30', 'PO_33', 'PO_38', 'PO_80', 'PO_83', 'PO_88']\n",
    "mask = df['Stimulus'].isin(order_1)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11,3))\n",
    "palette_color = ['#d62728', '#1f77b4']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            width=0.5, fill=False, linewidth=2, saturation=0, palette=palette_color, gap=.1,\n",
    "            order=order_1, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_1, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "# plotting Figure 4 c\n",
    "order_2 = ['GO_00', 'GO_03', 'GO_08', 'GO_30', 'GO_33', 'GO_38', 'GO_80', 'GO_83', 'GO_88']\n",
    "mask = df['Stimulus'].isin(order_2)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11,3))\n",
    "palette_color = ['#d62728', '#1f77b4']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            width=0.5, fill=False, linewidth=2, saturation=0, palette=palette_color, gap=.1,\n",
    "            order=order_2, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_2, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "ax.set_ylim([0, 8.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 1\n",
    "evs1 = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "evs2 = ['PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95']\n",
    "for ev in evs2:\n",
    "    df1 = df[df['Stimulus']==ev]\n",
    "    df2 = df1[df1['Hemisphere']=='lh']\n",
    "    mean = df2['EOG peak latency'].mean()\n",
    "    std = df2['EOG peak latency'].std()\n",
    "    print(f'{round(mean, 2)} + {round(std, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 2\n",
    "df1 = df[df['Stimulus']=='GO_60']\n",
    "df2 = df1[df1['Hemisphere']=='rh']\n",
    "median = round(df2['latency'].median(), 2)\n",
    "std = round(df2[\"latency\"].std(), 2)\n",
    "print(f'{median} + {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3\n",
    "evs1 = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240']\n",
    "evs2 = ['GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240']\n",
    "for ev in evs2:\n",
    "    df1 = df[df['Stimulus']==ev]\n",
    "    df2 = df1[df1['Hemisphere']=='lh']\n",
    "    mean = df2['amplitude inhibition (30ms)'].median()\n",
    "    std = df2['amplitude inhibition (30ms)'].std()\n",
    "    print(f'{round(mean, 2)} + {round(std, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tinmeg3 plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = ['GPP_00', 'GPG_00', 'PO_00', 'GO_00', 'PPP_00', 'PPG_00',\n",
    "        'GPP_03', 'GPG_03', 'PO_03', 'GO_03',\n",
    "        'GPP_08', 'GPG_08', 'PO_08', 'GO_08']\n",
    "# load dataframe and remove three subjects\n",
    "df = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg3_transverstemporal.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting 1\n",
    "order_1 = ['GPP_00', 'GPP_03', 'GPP_08']\n",
    "order_2 = ['GPG_00', 'GPG_03', 'GPG_08']\n",
    "\n",
    "mask = df['Stimulus'].isin(order_2)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "palette_color = ['#d62728', '#1f77b4']\n",
    "sns.boxplot(data=df1, x='Stimulus', y='area inhibition (30ms)', hue='Hemisphere', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, order=order_2, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='area inhibition (30ms)', hue='Hemisphere',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_2, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "ax.set_ylim([-100, 100])\n",
    "ax.hlines(0, -0.6, 2.6, colors='black',linestyles='--')\n",
    "ax.hlines(50, -0.6, 2.6, colors='grey',linestyles=':')\n",
    "\n",
    "# plotting 2\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg3_morphed'\n",
    "ev_name = 'GPP'\n",
    "stc_files_list_rh = {f'{ev_name}_00': [], f'{ev_name}_03': [], f'{ev_name}_08': []}\n",
    "stc_files_list_lh = {f'{ev_name}_00': [], f'{ev_name}_03': [], f'{ev_name}_08': []}\n",
    "events = [f'{ev_name}_00', f'{ev_name}_03', f'{ev_name}_08']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "\n",
    "for event in events:\n",
    "    for filename in sorted(os.listdir(directory)): \n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f: # or -rh\n",
    "                stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "                rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "                lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "                stc_files_list_rh[event].append(rh_data)\n",
    "                stc_files_list_lh[event].append(lh_data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "colors = ['#d62728', '#1f77b4', '#2ca02c'] \n",
    "for event, clr in zip(events, colors):\n",
    "    data = np.squeeze(np.array(stc_files_list_lh[event])).mean(axis=0)\n",
    "    ax.plot(np.linspace(-300, 300, 151), data.T, label=event, color=clr)\n",
    "ax.vlines(0, 0.5, 6, colors='black',linestyles='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='upper right', fontsize=9, frameon=False)\n",
    "ax.set_xlim([-310, 310])\n",
    "for i in [-300, -200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, 0.5, 6, colors='black',linestyles=':', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose what two columns to compare (EOG inhibition)\n",
    "df1 = df[df['Hemisphere']=='rh']\n",
    "for ev in ['GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240']:\n",
    "    column1 = df1[df1['Stimulus']=='PO70_90']['EOG area inhibition'] \n",
    "    column2 = df1[df1['Stimulus']==ev]['EOG area inhibition']\n",
    "    # Perform the t-test and df\n",
    "    t_stat, p_value = stats.ttest_ind(column1, column2, permutations=10000)\n",
    "    degree_freedom = len(column1) + len(column2) - 2\n",
    "    print(f'event={ev}, (df)={degree_freedom}, t_value={t_stat}, p_value={round(p_value,5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New series of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epochs dictionary (some needs concatenating)\n",
    "epochs_folder = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg2/epochs_bads_dropped'\n",
    "epochs_file = {}\n",
    "for f in sorted(os.listdir(epochs_folder)):\n",
    "    file = os.path.join(epochs_folder, f)\n",
    "    if file.endswith(\"-epo.fif\") and '697' not in file and '750' not in file and '853' not in file:\n",
    "        epochs_file[f'{file[-11:-8]}'] = file\n",
    "\n",
    "# compute evoked objects, and making grand average dictionary\n",
    "evs = []\n",
    "for ep_f in tqdm(list(epochs_file.values())):\n",
    "    evs.append(mne.read_epochs(fname=ep_f, verbose=False).average(picks=['meg', 'eog'], by_event_type=True))\n",
    "\n",
    "grnd_ev_dict = {}\n",
    "for stim_idx, stim in enumerate(list(events_dict_tinmeg2.keys())):\n",
    "    evs_stim = []\n",
    "    for ev in evs:\n",
    "        evs_stim.append(ev[stim_idx])\n",
    "    grnd_ev_dict[stim] = evs_stim\n",
    "\n",
    "grand_ev_dict_tinmeg2 = {}\n",
    "for stim in list(grnd_ev_dict.keys()):\n",
    "    grand_ev_dict_tinmeg2[stim] = mne.grand_average(grnd_ev_dict[stim])\n",
    "\n",
    "# Create epochs dictionary (some needs concatenating)\n",
    "epochs_folder = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg3/epochs_bads_dropped'\n",
    "epochs_file = {}\n",
    "for f in sorted(os.listdir(epochs_folder)):\n",
    "    file = os.path.join(epochs_folder, f)\n",
    "    if file.endswith(\"-epo.fif\") and '697' not in file and '750' not in file and '853' not in file:\n",
    "        epochs_file[f'{file[-12:-8]}'] = file\n",
    "\n",
    "# compute evoked objects, and making grand average dictionary\n",
    "evs = []\n",
    "for ep_f in tqdm(list(epochs_file.values())):\n",
    "    evs.append(mne.read_epochs(fname=ep_f, verbose=False).average(picks=['meg', 'eog'], by_event_type=True))\n",
    "\n",
    "grnd_ev_dict = {}\n",
    "for stim_idx, stim in enumerate(list(events_dict_tinmeg3.keys())):\n",
    "    evs_stim = []\n",
    "    for ev in evs:\n",
    "        evs_stim.append(ev[stim_idx])\n",
    "    grnd_ev_dict[stim] = evs_stim\n",
    "\n",
    "grand_ev_dict_tinmeg3 = {}\n",
    "for stim in list(grnd_ev_dict.keys()):\n",
    "    grand_ev_dict_tinmeg3[stim] = mne.grand_average(grnd_ev_dict[stim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting plots 1, 2, 3 from firsl line\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "colors = ['#ff7f0e', '#9467bd'] \n",
    "data1 = grand_ev_dict_tinmeg2['PO_08'].get_data(picks='EOG002')[0]\n",
    "data2 = grand_ev_dict_tinmeg2['GPP_08'].get_data(picks='EOG002')[0]\n",
    "data3 = grand_ev_dict_tinmeg3['PO_08'].get_data(picks='EOG002')[0]\n",
    "data4 = grand_ev_dict_tinmeg3['GPP_08'].get_data(picks='EOG002')[0]\n",
    "\n",
    "\n",
    "ax.plot(np.linspace(-300, 300, 151), data1*1e6, color=colors[0], label='Control (PO)')\n",
    "ax.plot(np.linspace(-300, 300, 151), data2*1e6, color=colors[1], label='Control (GPP)')\n",
    "ax.plot(np.linspace(-300, 300, 151), data3*1e6, linestyle='--', color=colors[0], label='Tinnitus (PO)')\n",
    "ax.plot(np.linspace(-300, 300, 151), data4*1e6, linestyle='--', color=colors[1], label='Tinnitus (GPP)')\n",
    "\n",
    "ax.vlines(0, -10, 30, colors='black',linestyles='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='best', fontsize=9, frameon=False)\n",
    "ax.set_xlim([-310, 310])\n",
    "ax.set_ylim([-10, 30])\n",
    "# for i in [-200, -100, 100, 200, 300]:\n",
    "#     ax.vlines(i, -10, 30, colors='black',linestyles=':', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting plots 1, 2, 3 from second and third line (you just need to set event name in ax function)\n",
    "# plotting 2\n",
    "directory1 = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg2_morphed'\n",
    "directory2 = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg3_morphed'\n",
    "events = ['PO_00', 'PO_03', 'PO_08', 'GPP_00', 'GPP_03', 'GPP_08']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "\n",
    "tinmeg2_stc_files_list_lh = {'PO_00': [], 'PO_03': [], 'PO_08': [], 'GPP_00': [], 'GPP_03': [], 'GPP_08': []}\n",
    "tinmeg2_stc_files_list_rh = {'PO_00': [], 'PO_03': [], 'PO_08': [], 'GPP_00': [], 'GPP_03': [], 'GPP_08': []}\n",
    "tinmeg3_stc_files_list_lh = {'PO_00': [], 'PO_03': [], 'PO_08': [], 'GPP_00': [], 'GPP_03': [], 'GPP_08': []}\n",
    "tinmeg3_stc_files_list_rh = {'PO_00': [], 'PO_03': [], 'PO_08': [], 'GPP_00': [], 'GPP_03': [], 'GPP_08': []}\n",
    "\n",
    "for ev in events:\n",
    "    for filename in sorted(os.listdir(directory1)): \n",
    "        f = os.path.join(directory1, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and ev in f: # or -rh\n",
    "            stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "            rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "            lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "            tinmeg2_stc_files_list_rh[ev].append(rh_data)\n",
    "            tinmeg2_stc_files_list_lh[ev].append(lh_data)\n",
    "\n",
    "for ev in events:\n",
    "    for filename in sorted(os.listdir(directory2)): \n",
    "        f = os.path.join(directory2, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and ev in f: # or -rh\n",
    "            stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "            rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "            lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "            tinmeg3_stc_files_list_rh[ev].append(rh_data)\n",
    "            tinmeg3_stc_files_list_lh[ev].append(lh_data)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "colors = ['#1f77b4', '#d62728'] \n",
    "data1 = np.squeeze(np.array(tinmeg2_stc_files_list_rh['PO_00'])).mean(axis=0)\n",
    "data2 = np.squeeze(np.array(tinmeg2_stc_files_list_rh['GPP_00'])).mean(axis=0)\n",
    "data3 = np.squeeze(np.array(tinmeg3_stc_files_list_rh['PO_00'])).mean(axis=0)\n",
    "data4 = np.squeeze(np.array(tinmeg3_stc_files_list_rh['GPP_00'])).mean(axis=0)\n",
    "\n",
    "ax.plot(np.linspace(-300, 300, 151), data1.T, color=colors[0])\n",
    "ax.plot(np.linspace(-300, 300, 151), data2.T, color=colors[1])\n",
    "ax.plot(np.linspace(-300, 300, 151), data3.T, color=colors[0], linestyle='--')\n",
    "ax.plot(np.linspace(-300, 300, 151), data4.T, color=colors[1], linestyle='--')\n",
    "\n",
    "ax.vlines(0, 0, 6, colors='black',linestyles='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_xlim([-310, 310])\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, 0.5, 6, colors='black',linestyles=':', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting inhibitions in tinmeg2 and tinmeg3 for GPP\n",
    "df_tinmeg2 = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg2_transverstemporal.csv')\n",
    "df_tinmeg3 = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg3_transverstemporal.csv')\n",
    "# updating dataframes and concatenating them\n",
    "df_tinmeg2 = df_tinmeg2.drop('EOG peak latency', axis=1)\n",
    "df_tinmeg2['Participants'] = len(df_tinmeg2) * ['tinmeg2']\n",
    "df_tinmeg3['Participants'] = len(df_tinmeg3) * ['tinmeg3']\n",
    "df = pd.concat([df_tinmeg2, df_tinmeg3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting inhibitions in tinmeg2 and tinmeg3 for GPP (EOG)\n",
    "order = ['GPP_00', 'GPP_03', 'GPP_08']\n",
    "df1 = df[df['Hemisphere']=='rh']\n",
    "mask = df1['Stimulus'].isin(order)\n",
    "df2 = df1[mask]\n",
    "palette_colors = ['#ff7f0e', '#9467bd'] \n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,4))\n",
    "# boxprops = {'linestyle': '-', 'linewidth': 2, 'color': 'grey'}\n",
    "sns.boxplot(data=df2, x='Stimulus', y='EOG area inhibition', hue='Participants', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0, palette=palette_colors, order=order, ax=ax)\n",
    "sns.stripplot(data=df2, x='Stimulus', y='EOG area inhibition', hue='Participants',\n",
    "            dodge=True, size=3, palette=palette_colors, order=order, ax=ax, legend=False)\n",
    "ax.set_ylim([-150, 150])\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right')\n",
    "ax.hlines(0, -0.6, 2.6, colors='black',linestyles='--')\n",
    "\n",
    "# plotting inhibitions in tinmeg2 and tinmeg3 for GPP (left hemisphere)\n",
    "order = ['GPP_00', 'GPP_03', 'GPP_08']\n",
    "df1 = df[df['Hemisphere']=='lh']\n",
    "mask = df1['Stimulus'].isin(order)\n",
    "df2 = df1[mask]\n",
    "palette_colors = ['#1f77b4', '#d62728']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,4))\n",
    "# boxprops = {'linestyle': '-', 'linewidth': 2, 'color': 'grey'}\n",
    "sns.boxplot(data=df2, x='Stimulus', y='area inhibition (30ms)', hue='Participants', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0, palette=palette_colors, order=order, ax=ax)\n",
    "sns.stripplot(data=df2, x='Stimulus', y='area inhibition (30ms)', hue='Participants',\n",
    "            dodge=True, size=3, palette=palette_colors, order=order, ax=ax, legend=False)\n",
    "ax.set_ylim([-150, 150])\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right')\n",
    "ax.hlines(0, -0.6, 2.6, colors='black',linestyles='--')\n",
    "\n",
    "# plotting inhibitions in tinmeg2 and tinmeg3 for GPP (right hemisphere)\n",
    "order = ['GPP_00', 'GPP_03', 'GPP_08']\n",
    "df1 = df[df['Hemisphere']=='rh']\n",
    "mask = df1['Stimulus'].isin(order)\n",
    "df2 = df1[mask]\n",
    "palette_colors = ['#1f77b4', '#d62728']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,4))\n",
    "# boxprops = {'linestyle': '-', 'linewidth': 2, 'color': 'grey'}\n",
    "sns.boxplot(data=df2, x='Stimulus', y='area inhibition (30ms)', hue='Participants', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0, palette=palette_colors, order=order, ax=ax)\n",
    "sns.stripplot(data=df2, x='Stimulus', y='area inhibition (30ms)', hue='Participants',\n",
    "            dodge=True, size=3, palette=palette_colors, order=order, ax=ax, legend=False)\n",
    "ax.set_ylim([-150, 150])\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper right')\n",
    "ax.hlines(0, -0.6, 2.6, colors='black',linestyles='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting gap only area values\n",
    "df1 = df[df['Hemisphere']=='rh'] # choosing the hemisphere\n",
    "df2 = df1[df1['Participants']=='tinmeg3'] # choosing only tinmeg3\n",
    "df3 = df2[df2['Stimulus']=='GO_08'] # choosing the stimulus for tinmeg3\n",
    "order = ['GO_08', 'GO_38', 'GO_88']\n",
    "mask = df1['Stimulus'].isin(order) # choosing the events for tinmeg2\n",
    "df4 = df1[mask]\n",
    "df5 = df4[df4['Participants']=='tinmeg2']\n",
    "df6 = pd.concat([df3, df5])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,4))\n",
    "sns.barplot(data=df6, x='Stimulus', y='area value (30ms)', hue='Participants', fill=False, gap=.5, linewidth=2,\n",
    "            capsize=.1, err_kws={\"color\": \".5\", \"linewidth\": 2.5}, width=1.2, saturation=0, palette=palette_colors,\n",
    "            order=order, legend=False, ax=ax)\n",
    "ax.legend(frameon=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.set_ylim([0, 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting inhibition values for different noise carrier conditions (NBN and BBN)\n",
    "df1 = df[df['Hemisphere']=='rh'] # choosing the hemisphere\n",
    "df2 = df1[df1['Participants']=='tinmeg2'] # choosing only tinmeg2\n",
    "order = ['GPP_08', 'GPP_38', 'GPP_88']\n",
    "mask = df2['Stimulus'].isin(order) # choosing the events for tinmeg2\n",
    "df3 = df2[mask]\n",
    "\n",
    "# palette_colors1 = ['#ff7f0e', '#9467bd', '#17becf']\n",
    "palette_colors1 = ['#1f77b4', '#2ca02c', '#d62728']\n",
    "palette_colors2 = ['k', 'k', 'k']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "sns.boxplot(data=df3, x='Stimulus', y='area inhibition (30ms)', width=0.8, fill=True, gap=.1, linewidth=2,\n",
    "            saturation=0.75, palette=palette_colors1, order=order, ax=ax)\n",
    "sns.stripplot(data=df3, x='Stimulus', y='EOG area inhibition',\n",
    "            dodge=False, size=3, palette=palette_colors2, order=order, ax=ax)\n",
    "ax.legend(frameon=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.set_ylim([-150, 120])\n",
    "ax.hlines(0, -0.6, 2.6, colors='black',linestyles='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting table values to estimate ICC\n",
    "df_tinmeg1 = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv')\n",
    "df_tinmeg2 = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg2_transverstemporal.csv')\n",
    "\n",
    "# tinmeg1\n",
    "df1 = df_tinmeg1[df_tinmeg1['Stimulus']=='GP60_i240']\n",
    "df2 = df1[df1['Hemisphere']=='rh']\n",
    "order = [539, 842, 849, 840, 863, 862, 850, 832, 861]\n",
    "mask = df2['subject ID'].isin(order) # choosing the events for tinmeg2\n",
    "df3 = df2[mask]\n",
    "df3[['subject ID', 'area inhibition (30ms)']]\n",
    "\n",
    "# tinmeg2\n",
    "df1 = df_tinmeg2[df_tinmeg2['Stimulus']=='PO_00']\n",
    "df2 = df1[df1['Hemisphere']=='lh']\n",
    "order = [916, 979, 981, 982, 984, 983, 980, 986, 988]\n",
    "mask = df2['subject ID'].isin(order) # choosing the events for tinmeg2\n",
    "df3 = df2[mask]\n",
    "df3[['subject ID', 'area value (30ms)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new series of plots after fixing tinmeg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = [916, 979, 980, 982, 983, 986, 988] # drop 981, 984\n",
    "evs_gpp = []; evs_gpp_3 = []; evs_gpp_8 = []\n",
    "evs_po = []; evs_po_3 = []; evs_po_8 = []\n",
    "for id in sub_list:\n",
    "    fname = f'/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg2/epochs_bads_dropped/epochs_subject_{id}-epo.fif'\n",
    "    epochs = mne.read_epochs(fname=fname, preload=True)\n",
    "    ev = epochs.average(picks=['meg', 'eog'], by_event_type=True)\n",
    "    evs_gpp.append(ev[0]) \n",
    "    evs_po.append(ev[2])\n",
    "    evs_gpp_3.append(ev[6]) \n",
    "    evs_po_3.append(ev[8])\n",
    "    evs_gpp_8.append(ev[10])  \n",
    "    evs_po_8.append(ev[12])\n",
    "\n",
    "grand_ev_gpp = mne.grand_average(evs_gpp)\n",
    "grand_ev_po = mne.grand_average(evs_po)\n",
    "grand_ev_gpp_3 = mne.grand_average(evs_gpp_3)\n",
    "grand_ev_po_3 = mne.grand_average(evs_po_3)\n",
    "grand_ev_gpp_8 = mne.grand_average(evs_gpp_8)\n",
    "grand_ev_po_8 = mne.grand_average(evs_po_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traces in max channel\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "data1 = grand_ev_po_8.get_data(picks='MEG1332')\n",
    "data2 = grand_ev_gpp_8.get_data(picks='MEG1332')\n",
    "\n",
    "ax.plot(np.linspace(-300, 300, 151), data1.T * 1e13, color=colors[0], label='PO')\n",
    "ax.plot(np.linspace(-300, 300, 151), data2.T * 1e13, color=colors[1], label='GPP')\n",
    "ax.vlines(0, -50, 120, colors='black',linestyles='--')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend(loc='best', fontsize=9, frameon=False)\n",
    "ax.set_xlim([-310, 310])\n",
    "ax.set_ylim([-50, 120])\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    ax.vlines(i, -50, 120, colors='black',linestyles=':', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensor plots of tinmeg1 for supplementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epochs dictionary (some needs concatenating)\n",
    "epochs_folder = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg1'\n",
    "epochs_file = {}\n",
    "for f in sorted(os.listdir(epochs_folder)):\n",
    "    file = os.path.join(epochs_folder, f)\n",
    "    if file.endswith(\"-epo.fif\"):\n",
    "        epochs_file[f'{file[-11:-8]}'] = file\n",
    "\n",
    "# Create epochs dictionary (some needs concatenating)\n",
    "epochs_folder = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg1'\n",
    "epochs_file = {}\n",
    "for f in sorted(os.listdir(epochs_folder)):\n",
    "    file = os.path.join(epochs_folder, f)\n",
    "    if file.endswith(\"-epo.fif\") and '697' not in file and '750' not in file and '853' not in file:\n",
    "        epochs_file[f'{file[-11:-8]}'] = file\n",
    "\n",
    "# compute evoked objects, and making grand average dictionary\n",
    "evs = []\n",
    "for ep_f in tqdm(list(epochs_file.values())):\n",
    "    evs.append(mne.read_epochs(fname=ep_f, verbose=False).average(picks=['meg', 'eog'], by_event_type=True))\n",
    "\n",
    "grnd_ev_dict = {}\n",
    "for stim_idx, stim in enumerate(list(events_dict_tinmeg1.keys())):\n",
    "    evs_stim = []\n",
    "    for ev in evs:\n",
    "        evs_stim.append(ev[stim_idx])\n",
    "    grnd_ev_dict[stim] = evs_stim\n",
    "\n",
    "grand_ev_dict = {}\n",
    "for stim in list(grnd_ev_dict.keys()):\n",
    "    grand_ev_dict[stim] = mne.grand_average(grnd_ev_dict[stim])\n",
    "\n",
    "# separate chanels on left and right\n",
    "info_ch = evs[0][0].info['chs']\n",
    "meg_chs_right = []; meg_chs_left = []\n",
    "grad_chs_right = []; grad_chs_left = []\n",
    "for i in range(len(info_ch)):\n",
    "    if info_ch[i]['unit'] == 112: # meg code\n",
    "        if info_ch[i]['loc'][0] > 0:\n",
    "            meg_chs_right.append(info_ch[i]['ch_name'])\n",
    "        if info_ch[i]['loc'][0] < 0:\n",
    "            meg_chs_left.append(info_ch[i]['ch_name'])\n",
    "    if info_ch[i]['unit'] == 201: # grad code\n",
    "        if info_ch[i]['loc'][0] > 0:\n",
    "            grad_chs_right.append(info_ch[i]['ch_name'])\n",
    "        if info_ch[i]['loc'][0] < 0:\n",
    "            grad_chs_left.append(info_ch[i]['ch_name'])\n",
    "\n",
    "# select the left/ channels with largest ptp amplitude\n",
    "ev_data_left = grand_ev_dict['PO60_70'].get_data(picks=grad_chs_left)\n",
    "ev_data_right = grand_ev_dict['PO60_70'].get_data(picks=grad_chs_right)\n",
    "max_values = []\n",
    "for ch_idx in range(len(ev_data_left)):\n",
    "    max_values.append(ev_data_left[ch_idx][50:150].max())\n",
    "ch_max_left = grad_chs_left[np.argmax(np.array(max_values))]\n",
    "max_values = []\n",
    "for ch_idx in range(len(ev_data_right)):\n",
    "    max_values.append(ev_data_right[ch_idx][50:150].max())\n",
    "ch_max_right = grad_chs_right[np.argmax(np.array(max_values))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a dataframe for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making big dataframe for transverstemporal rh/lh\n",
    "my_dict = {'subject ID': [], 'Stimulus': [], 'Ch_name': [],\n",
    "        'peak value (30ms)': [], 'peak value (100ms)': [], 'area value (30ms)': [],\n",
    "        'area value (100ms)': [], 'amplitude inhibition (30ms)': [],\n",
    "        'area inhibition (30ms)': [], 'amplitude inhibition (100ms)': [],\n",
    "        'area inhibition (100ms)': []} \n",
    "\n",
    "events = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95',\n",
    "        'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95',\n",
    "        'GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240',\n",
    "        'GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240',\n",
    "        'GO_60', 'GO_70']\n",
    "\n",
    "subjects = ['539', '756', '832', '835', '836', '838', '839', '840',\n",
    "        '841', '842', '844', '845', '847', '849','850', '852',\n",
    "        '856', '857', '858', '859', '861', '862', '863'] \n",
    "\n",
    "chs = [ch_max_left, ch_max_right]\n",
    "combinations = product(subjects, events, chs)\n",
    "\n",
    "for subject, stim, ch in tqdm(combinations):\n",
    "                \n",
    "        # reading epoch file \n",
    "        fname = epochs_file[subject]\n",
    "        ep = mne.read_epochs(fname=fname, preload=True, verbose=False)[stim]\n",
    "        ep_data = np.squeeze(ep.get_data(picks=ch)).mean(axis=0) \n",
    "\n",
    "        # computing some params  \n",
    "        ep_peak_100ms = ep_data[87:114].max()\n",
    "        ep_peak_30ms = ep_data[96:105].max()\n",
    "        ep_area_100ms = ep_data[87:114].sum()\n",
    "        ep_area_30ms = ep_data[96:105].sum()\n",
    "        \n",
    "        if '60' in stim and '70' not in stim:\n",
    "                ep_stn = mne.read_epochs(fname=fname, preload=True, verbose=False)['PO60_90']\n",
    "                ep_stn_data = np.squeeze(ep_stn.get_data(picks=ch)).mean(axis=0)\n",
    "                ep_stn_peak_100ms = ep_stn_data[87:114].max()\n",
    "                ep_stn_peak_30ms = ep_stn_data[96:105].max()\n",
    "                ep_stn_area_100ms = ep_stn_data[87:114].sum()\n",
    "                ep_stn_area_30ms = ep_stn_data[96:105].sum()\n",
    "        if '70' in stim:\n",
    "                ep_stn = mne.read_epochs(fname=fname, preload=True, verbose=False)['PO70_90']\n",
    "                ep_stn_data = np.squeeze(ep_stn.get_data(picks=ch)).mean(axis=0)\n",
    "                ep_stn_peak_100ms = ep_stn_data[87:114].max()\n",
    "                ep_stn_peak_30ms = ep_stn_data[96:105].max()\n",
    "                ep_stn_area_100ms = ep_stn_data[87:114].sum()\n",
    "                ep_stn_area_30ms = ep_stn_data[96:105].sum()\n",
    "\n",
    "        # computing inhibition indexes \n",
    "        my_dict['amplitude inhibition (30ms)'].append((1 - (ep_peak_30ms / ep_stn_peak_30ms)) * 100)\n",
    "        my_dict['area inhibition (30ms)'].append((1 - (ep_area_30ms / ep_stn_area_30ms)) * 100)\n",
    "        my_dict['amplitude inhibition (100ms)'].append((1 - (ep_peak_100ms / ep_stn_peak_100ms)) * 100)\n",
    "        my_dict['area inhibition (100ms)'].append((1 - (ep_area_100ms / ep_stn_area_100ms)) * 100)\n",
    "\n",
    "        # putting in the dictionary\n",
    "        my_dict['subject ID'].append(subject)\n",
    "        my_dict['Stimulus'].append(stim)\n",
    "        my_dict['Ch_name'].append(ch)\n",
    "        my_dict['peak value (30ms)'].append(ep_peak_30ms)\n",
    "        my_dict['peak value (100ms)'].append(ep_peak_100ms)\n",
    "        my_dict['area value (30ms)'].append(ep_area_30ms)\n",
    "        my_dict['area value (100ms)'].append(ep_area_100ms)\n",
    "\n",
    "df = pd.DataFrame(my_dict)\n",
    "# save it\n",
    "df.to_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_sensors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_sensors.csv')\n",
    "\n",
    "# Supplementary figure A\n",
    "order_1 = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "order_2 = ['PO60_70', 'PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95']\n",
    "mask = df['Stimulus'].isin(order_2)\n",
    "df1 = df[mask]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,4))\n",
    "palette_color = ['#1f77b4', '#d62728'] \n",
    "sns.boxplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Ch_name', width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, order=order_2, ax=ax)\n",
    "sns.stripplot(data=df1, x='Stimulus', y='peak value (30ms)', hue='Ch_name',\n",
    "            dodge=True, size=3, palette=palette_color, order=order_2, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)\n",
    "ax.legend(frameon=False, loc='upper left')\n",
    "ax.set_yticks(np.array([0, 0.5, 1, 1.5])*1e-11)\n",
    "\n",
    "# supplementary figure B\n",
    "fig, axs = plt.subplots(1, 1, figsize=(7, 3))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "# stims = ['PO70_75', 'PO70_80', 'PO70_85', 'PO70_90', 'PO70_95']\n",
    "colors = ['#1f77b4', '#d62728']\n",
    "color = colors[0]\n",
    "lw = 0.5\n",
    "for stim in stims[:-1]:\n",
    "    axs.plot(time_array, abs(grand_ev_dict[stim].get_data(picks=ch_max_left)[0] * 1e15),\n",
    "            linewidth=lw, label=stim, color=color)\n",
    "    lw += 0.4\n",
    "for stim in stims[-1:]:\n",
    "    axs.plot(time_array, abs(grand_ev_dict[stim].get_data(picks=ch_max_left)[0] * 1e15),\n",
    "            linewidth=lw, label=stim, color='k')\n",
    "    \n",
    "axs.axvspan(50, 150, alpha=0.4, color='lightgrey')\n",
    "# axs.legend(fontsize=9, frameon=False, bbox_to_anchor=(0.5, 0.1, 0.6, 0.6))\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    axs.vlines(i, -1000, 10000, colors='black',linestyles=':', linewidth=0.5)\n",
    "axs.vlines(0, -1000, 10000, colors='black',linestyles='--')\n",
    "axs.set_ylabel(f'fT/cm')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_ylim([-1000, 10000])\n",
    "\n",
    "# supplementary figure B\n",
    "info = grand_ev_dict['PO60_70'].pick('grad').info\n",
    "kwargs = dict(eeg=False, coord_frame=\"mag\")\n",
    "n_chs = len(info['ch_names'])\n",
    "sensor_colors = np.zeros(shape=(n_chs, 4)) + matplotlib.colors.to_rgba_array('grey', alpha=0.3)\n",
    "left_idx = info['ch_names'].index(ch_max_left)\n",
    "right_idx = info['ch_names'].index(ch_max_right)\n",
    "sensor_colors[left_idx] = matplotlib.colors.to_rgba_array('#1f77b4', alpha=None)\n",
    "sensor_colors[right_idx] = matplotlib.colors.to_rgba_array('#d62728', alpha=None)\n",
    "\n",
    "fig = mne.viz.create_3d_figure((600, 600), bgcolor=(255, 255, 255))\n",
    "mne.viz.plot_alignment(info=info, surfaces='auto', coord_frame='auto',\n",
    "                    meg='sensors', eeg=False, ecog=True, fig=fig,\n",
    "                    dbs=False, interaction='terrain', sensor_colors=sensor_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two-way ANOVA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source\n",
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv\")\n",
    "mask = df['subject ID'].isin([697, 750, 853, 841]) # 841 is just for fun\n",
    "df = df[~mask]\n",
    "selected_columns = ['subject ID', 'Stimulus', 'Hemisphere', 'area inhibition (30ms)', 'EOG area inhibition']\n",
    "df = df[selected_columns]\n",
    "\n",
    "conditions = [\n",
    "    df['Stimulus'].str.endswith('_i0'),\n",
    "    df['Stimulus'].str.endswith('_i60'),\n",
    "    df['Stimulus'].str.endswith('_i120'),\n",
    "    df['Stimulus'].str.endswith('_i240')\n",
    "]\n",
    "choices = ['0', '60', '120', '240']\n",
    "df['Inter Stimulus Interval'] = np.select(conditions, choices, default=np.nan)\n",
    "mask = df.apply(lambda row: any(['nan' in str(cell) for cell in row]), axis=1)\n",
    "df = df[~mask]\n",
    "df['Pulse level'] = df['Stimulus'].apply(lambda x: '60' if x.startswith('GP60') else ('70' if x.startswith('GP70') else None))\n",
    "df = df.rename(columns={'subject ID': 'ID', 'area inhibition (30ms)': 'II',\n",
    "                        'EOG area inhibition': 'EOG_II',\n",
    "                        'Inter Stimulus Interval': 'ISI',\n",
    "                        'Pulse level': 'PL'})\n",
    "df_rh = df[df['Hemisphere'] == 'rh']\n",
    "df_lh = df[df['Hemisphere'] == 'lh']\n",
    "\n",
    "## checking for missing values\n",
    "assert not sum(df.isnull().sum()), \"There are missing values\" \n",
    "\n",
    "## removing outliers\n",
    "# thr = 3\n",
    "# z_scores_rh = stats.zscore(df_rh['II'])\n",
    "# z_scores_lh = stats.zscore(df_lh['II'])\n",
    "# z_scores_eog = stats.zscore(df_rh['EOG_II'])\n",
    "\n",
    "# df_rh = df_rh[~(abs(z_scores_rh) > thr)]\n",
    "# df_lh = df_lh[~(abs(z_scores_lh) > thr)]\n",
    "# df_eog = df_rh[~(abs(z_scores_eog) > thr)]\n",
    "\n",
    "## performing two-way ANOVA\n",
    "model_rh = ols(formula='II ~ ISI + PL + ISI:PL',\n",
    "            data=df_rh,\n",
    "            drop_cols=['ID', 'Stimulus', 'Hemisphere', 'EOG_II']).fit()\n",
    "model_lh = ols(formula='II ~ ISI + PL + ISI:PL',\n",
    "            data=df_lh,\n",
    "            drop_cols=['ID', 'Stimulus', 'Hemisphere', 'EOG_II']).fit()\n",
    "model_eog = ols(formula='EOG_II ~ ISI + PL + ISI:PL',\n",
    "            data=df_rh,\n",
    "            drop_cols=['ID', 'Stimulus', 'Hemisphere', 'II']).fit()\n",
    "\n",
    "## performing LLM\n",
    "result_llm_rh = smf.mixedlm(\"II ~ ISI + PL\", df_rh, groups=df_rh.index).fit()\n",
    "result_llm_lh = smf.mixedlm(\"II ~ ISI + PL\", df_lh, groups=df_lh.index).fit()\n",
    "# result_llm_eog = smf.mixedlm(\"II ~ ISI + PL\", df_eog, groups=df_eog.index).fit()\n",
    "\n",
    "## checking normality with Shapiro-Wilk test\n",
    "for model, title in zip([model_rh, model_lh, model_eog], [\"rh\", \"lh\", \"eog\"]):\n",
    "    residuals = model.resid\n",
    "    shapiro_test_residuals = stats.shapiro(residuals)\n",
    "    # print(f\"Shapiro-Wilk test for residuals in {title}:\", shapiro_test_residuals)\n",
    "\n",
    "table_rh = sm.stats.anova_lm(model_rh, typ=2)\n",
    "table_lh = sm.stats.anova_lm(model_lh, typ=2)\n",
    "table_eog = sm.stats.anova_lm(model_eog, typ=2)\n",
    "\n",
    "## ANOVA repeated measure\n",
    "aovrm2way_rh = AnovaRM(df_rh, \"II\", \"ID\", within=[\"ISI\", \"PL\"]).fit()\n",
    "aovrm2way_lh = AnovaRM(df_lh, \"II\", \"ID\", within=[\"ISI\", \"PL\"]).fit()\n",
    "aovrm2way_eog = AnovaRM(df_rh, \"EOG_II\", \"ID\", within=[\"ISI\", \"PL\"]).fit()\n",
    "\n",
    "## tukey multi comparison\n",
    "tukey_rh = MultiComparison(data=df_rh['II'], groups=df_rh['ISI']).tukeyhsd() # could be changed to PL\n",
    "tukey_lh = MultiComparison(data=df_lh['II'], groups=df_lh['ISI']).tukeyhsd()\n",
    "tukey_eog = MultiComparison(data=df_rh['EOG_II'], groups=df_rh['ISI']).tukeyhsd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sensor\n",
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_sensors.csv\")\n",
    "mask = df['subject ID'].isin([697, 750, 853, 841])\n",
    "df = df[~mask]\n",
    "selected_columns = ['subject ID', 'Stimulus', 'Ch_name', 'area inhibition (30ms)']\n",
    "df = df[selected_columns]\n",
    "\n",
    "conditions = [\n",
    "    df['Stimulus'].str.endswith('_i0'),\n",
    "    df['Stimulus'].str.endswith('_i60'),\n",
    "    df['Stimulus'].str.endswith('_i120'),\n",
    "    df['Stimulus'].str.endswith('_i240')\n",
    "]\n",
    "choices = ['0', '60', '120', '240']\n",
    "df['Inter Stimulus Interval'] = np.select(conditions, choices, default=np.nan)\n",
    "mask = df.apply(lambda row: any(['nan' in str(cell) for cell in row]), axis=1)\n",
    "df = df[~mask]\n",
    "df['Pulse level'] = df['Stimulus'].apply(lambda x: '60' if x.startswith('GP60') else ('70' if x.startswith('GP70') else None))\n",
    "df = df.rename(columns={'subject ID': 'ID', 'area inhibition (30ms)': 'II',\n",
    "                        'Inter Stimulus Interval': 'ISI',\n",
    "                        'Pulse level': 'PL'})\n",
    "df_rh = df[df['Ch_name'] == 'MEG1332']\n",
    "df_lh = df[df['Ch_name'] == 'MEG0242']\n",
    "\n",
    "## removing outliers\n",
    "# thr = 3\n",
    "# z_scores_rh = stats.zscore(df_rh['II'])\n",
    "# z_scores_lh = stats.zscore(df_lh['II'])\n",
    "\n",
    "# df_rh = df_rh[~(abs(z_scores_rh) > thr)]\n",
    "# df_lh = df_lh[~(abs(z_scores_lh) > thr)]\n",
    "\n",
    "## performing two-way ANOVA and tukey test\n",
    "model_rh = ols(formula='II ~ C(ISI) + C(PL) + C(ISI):C(PL)',\n",
    "            data=df_rh,\n",
    "            drop_cols=['ID', 'Stimulus', 'Ch_name', 'EOG_II']).fit()\n",
    "model_lh = ols(formula='II ~ C(ISI) + C(PL) + C(ISI):C(PL)',\n",
    "            data=df_lh,\n",
    "            drop_cols=['ID', 'Stimulus', 'Ch_name', 'EOG_II']).fit()\n",
    "\n",
    "table_rh = sm.stats.anova_lm(model_rh, typ=2)\n",
    "table_lh = sm.stats.anova_lm(model_lh, typ=2)\n",
    "\n",
    "## ANOVA repeated measure\n",
    "aovrm2way_rh = AnovaRM(df_rh, \"II\", \"ID\", within=[\"ISI\", \"PL\"]).fit()\n",
    "aovrm2way_lh = AnovaRM(df_lh, \"II\", \"ID\", within=[\"ISI\", \"PL\"]).fit()\n",
    "\n",
    "tukey_rh = MultiComparison(data=df_rh['II'], groups=df_rh['ISI']).tukeyhsd() # could be changed to PL\n",
    "tukey_lh = MultiComparison(data=df_lh['II'], groups=df_lh['ISI']).tukeyhsd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source\n",
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv\")\n",
    "mask = df['subject ID'].isin([697, 750, 853, 841]) # 841 is just for fun\n",
    "df = df[~mask]\n",
    "selected_columns = ['subject ID', 'Stimulus', 'Hemisphere', 'area inhibition (30ms)', 'EOG area inhibition']\n",
    "df = df[selected_columns]\n",
    "\n",
    "conditions = [\n",
    "    df['Stimulus'].str.endswith('_i0'),\n",
    "    df['Stimulus'].str.endswith('_i60'),\n",
    "    df['Stimulus'].str.endswith('_i120'),\n",
    "    df['Stimulus'].str.endswith('_i240')\n",
    "]\n",
    "choices = ['0', '60', '120', '240']\n",
    "df['Inter Stimulus Interval'] = np.select(conditions, choices, default=np.nan)\n",
    "mask = df.apply(lambda row: any(['nan' in str(cell) for cell in row]), axis=1)\n",
    "df = df[~mask]\n",
    "df['Pulse level'] = df['Stimulus'].apply(lambda x: '60' if x.startswith('GP60') else ('70' if x.startswith('GP70') else None))\n",
    "df = df.rename(columns={'subject ID': 'ID', 'area inhibition (30ms)': 'II',\n",
    "                        'EOG area inhibition': 'EOG_II',\n",
    "                        'Inter Stimulus Interval': 'ISI',\n",
    "                        'Pulse level': 'PL'})\n",
    "df_rh = df[df['Hemisphere'] == 'rh']\n",
    "df_lh = df[df['Hemisphere'] == 'lh']\n",
    "\n",
    "## checking for missing values\n",
    "assert not sum(df.isnull().sum()), \"There are missing values\" \n",
    "\n",
    "## ta king only positive values\n",
    "df_rh = df_rh[df_rh[\"II\"] > 0]\n",
    "df_rh = df_rh[df_rh[\"EOG_II\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(11, 5))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "axes = list(product(range(2), range(4)))\n",
    "stims = [\"GP60_i0\", \"GP60_i60\", \"GP60_i120\", \"GP60_i240\",\n",
    "        \"GP70_i0\", \"GP70_i60\", \"GP70_i120\", \"GP70_i240\"]\n",
    "(x, y) = (\"II\", \"EOG_II\")\n",
    "cmap = plt.get_cmap(\"Set1\")\n",
    "\n",
    "# plotting the scatter plot\n",
    "for (i , j), stim in zip(axes, stims):\n",
    "    \n",
    "    df_s = df_rh[df[\"Stimulus\"]==stim]\n",
    "    scatter_kws = {\"s\": 10, \"color\": cmap.colors[j]}\n",
    "    line_kws = {\"linestyle\": \"--\", \"linewidth\": 1, \"color\": \"k\"}\n",
    "    sns.regplot(data=df_s, x=x, y=y, ax=axs[i][j], ci=95, scatter_kws=scatter_kws,\n",
    "                line_kws=line_kws)\n",
    "    axs[i][j].set_xlabel(\"\")\n",
    "    axs[i][j].set_ylabel(\"\")\n",
    "    axs[i][j].spines[['right', 'top']].set_visible(False)\n",
    "    axs[i][j].set_xlim([-10, 110])\n",
    "    axs[i][j].set_ylim([-10, 110])\n",
    "\n",
    "    # to print p and r values\n",
    "    X = sm.add_constant(df_s[x]) \n",
    "    model = sm.GLS(df_s[y], X)\n",
    "    results = model.fit()\n",
    "    axs[i][j].set_title(f\"R_const:{round(results.params.const, 3)}, R_ii:{round(results.params.II, 3)}\\n p_const:{round(results.pvalues.const, 3)}, p_ii:{round(results.pvalues.II, 3)}\", fontsize=6)\n",
    "\n",
    "\n",
    "axs[0][0].set_ylabel(\"EOG Inhibition\")\n",
    "axs[1][0].set_ylabel(\"EOG Inhibition\")\n",
    "# for i, title, xlabel in zip(range(4), [\"0 ms\", \"60 ms\", \"120 ms\", \"240 ms\"], [\"Inhibition Index\"] * 4):\n",
    "#     axs[0][i].set_title(title)\n",
    "#     axs[1][i].set_xlabel(xlabel)\n",
    "\n",
    "axs[0][3].yaxis.set_label_position(\"right\")\n",
    "axs[1][3].yaxis.set_label_position(\"right\")\n",
    "\n",
    "axs[0][3].set_ylabel(\"Noise Level 60\", rotation=270)\n",
    "axs[1][3].set_ylabel(\"Noise Level 70\", rotation=270)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonical Correlation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source\n",
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv\")\n",
    "mask = df['subject ID'].isin([697, 750, 853, 841]) # 841 is just for fun\n",
    "df = df[~mask]\n",
    "selected_columns = ['subject ID', 'Stimulus', 'Hemisphere', 'area inhibition (30ms)', 'EOG area inhibition']\n",
    "df = df[selected_columns]\n",
    "\n",
    "conditions = [\n",
    "    df['Stimulus'].str.endswith('_i0'),\n",
    "    df['Stimulus'].str.endswith('_i60'),\n",
    "    df['Stimulus'].str.endswith('_i120'),\n",
    "    df['Stimulus'].str.endswith('_i240')\n",
    "]\n",
    "choices = ['0', '60', '120', '240']\n",
    "df['Inter Stimulus Interval'] = np.select(conditions, choices, default=np.nan)\n",
    "mask = df.apply(lambda row: any(['nan' in str(cell) for cell in row]), axis=1)\n",
    "df = df[~mask]\n",
    "df['Pulse level'] = df['Stimulus'].apply(lambda x: '60' if x.startswith('GP60') else ('70' if x.startswith('GP70') else None))\n",
    "df = df.rename(columns={'subject ID': 'ID', 'area inhibition (30ms)': 'II',\n",
    "                        'EOG area inhibition': 'EOG_II',\n",
    "                        'Inter Stimulus Interval': 'ISI',\n",
    "                        'Pulse level': 'PL'})\n",
    "df_rh = df[df['Hemisphere'] == 'rh']\n",
    "df_lh = df[df['Hemisphere'] == 'lh']\n",
    "\n",
    "## checking for missing values\n",
    "assert not sum(df.isnull().sum()), \"There are missing values\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(11, 5))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "axes = list(product(range(2), range(4)))\n",
    "stims = [\"GP60_i0\", \"GP60_i60\", \"GP60_i120\", \"GP60_i240\",\n",
    "        \"GP70_i0\", \"GP70_i60\", \"GP70_i120\", \"GP70_i240\"]\n",
    "cmap = plt.get_cmap(\"Set1\")\n",
    "df_rh = df[df['Hemisphere'] == 'rh']\n",
    "df_lh = df[df['Hemisphere'] == 'lh']\n",
    "\n",
    "for (i , j), stim in zip(axes, stims):\n",
    "    # create the dataframe\n",
    "    df1 = df_rh[df_rh[\"Stimulus\"]==stim]\n",
    "    df2 = df_lh[df_lh[\"Stimulus\"]==stim]\n",
    "    new_df_dict = {\"Stimulus\": [stim]*len(df1),\n",
    "                    \"right_II\": np.array(df1[\"II\"]),\n",
    "                    \"left_II\": np.array(df2[\"II\"]),\n",
    "                    \"EOG_II\": np.array(df1[\"EOG_II\"])}\n",
    "    df_both = pd.DataFrame(new_df_dict)\n",
    "    df_both = df_both[(df_both[\"right_II\"]>0) & (df_both[\"left_II\"]>0) & (df_both[\"EOG_II\"]>0)]\n",
    "\n",
    "    ## CC analysis\n",
    "    X = df_both[[\"left_II\", \"right_II\"]]\n",
    "    Y = df_both[\"EOG_II\"]\n",
    "    cca = CCA(n_components=1)\n",
    "    cca.fit(X, Y)\n",
    "    X_c, Y_c = cca.transform(X, Y)\n",
    "\n",
    "    ## plotting\n",
    "    scatter_kws = {\"s\": 10, \"color\": cmap.colors[j]}\n",
    "    line_kws = {\"linestyle\": \"--\", \"linewidth\": 1, \"color\": \"k\"}\n",
    "    sns.regplot(data=df_both, x=X_c, y=Y_c, ax=axs[i][j], ci=95, scatter_kws=scatter_kws,\n",
    "                line_kws=line_kws)\n",
    "    axs[i][j].set_xlabel(\"\")\n",
    "    axs[i][j].set_ylabel(\"\")\n",
    "    axs[i][j].spines[['right', 'top']].set_visible(False)\n",
    "    axs[i][j].set_xlim([-2.5, 2.5])\n",
    "    axs[i][j].set_ylim([-2.5, 2.5])\n",
    "\n",
    "    # to print p and r values\n",
    "    sm_x = sm.add_constant(X_c) \n",
    "    model = sm.GLS(Y_c, sm_x)\n",
    "    results = model.fit()\n",
    "    axs[i][j].set_title(f\"R_const:{round(results.params[0], 3)}, R_ii:{round(results.params[1], 3)}\\n p_const:{round(results.pvalues[0], 3)}, p_ii:{round(results.pvalues[1], 3)}\", fontsize=6)\n",
    "\n",
    "\n",
    "axs[0][0].set_ylabel(\"EOG Inhibition\")\n",
    "axs[1][0].set_ylabel(\"EOG Inhibition\")\n",
    "# for i, title, xlabel in zip(range(4), [\"0 ms\", \"60 ms\", \"120 ms\", \"240 ms\"], [\"Inhibition Index\"] * 4):\n",
    "#     axs[0][i].set_title(title)\n",
    "#     axs[1][i].set_xlabel(xlabel)\n",
    "\n",
    "axs[0][3].yaxis.set_label_position(\"right\")\n",
    "axs[1][3].yaxis.set_label_position(\"right\")\n",
    "\n",
    "axs[0][3].set_ylabel(\"Noise Level 60\", rotation=270)\n",
    "axs[1][3].set_ylabel(\"Noise Level 70\", rotation=270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulse Only Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source\n",
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv\")\n",
    "mask = df['subject ID'].isin([697, 750, 853, 841]) # 841 is just for fun\n",
    "df = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source\n",
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv\")\n",
    "mask = df['subject ID'].isin([697, 750, 853, 841]) # 841 is just for fun\n",
    "df = df[~mask]\n",
    "selected_columns = ['subject ID', 'Stimulus', 'Hemisphere', 'area value (30ms)', 'EOG area (30ms)']\n",
    "df = df[selected_columns]\n",
    "df_rh = df[df['Hemisphere'] == 'rh']\n",
    "df_lh = df[df['Hemisphere'] == 'lh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6, 2))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "axes = range(2)\n",
    "stims = [\"PO60_90\", \"PO70_90\"]\n",
    "(x, y) = (\"area value (30ms)\", \"EOG area (30ms)\")\n",
    "cmap = plt.get_cmap(\"Set1\")\n",
    "\n",
    "# plotting the scatter plot\n",
    "for i, stim in zip(axes, stims):\n",
    "    \n",
    "    df_s = df_rh[df_rh[\"Stimulus\"]==stim]\n",
    "\n",
    "    scatter_kws = {\"s\": 10, \"color\": cmap.colors[j]}\n",
    "    line_kws = {\"linestyle\": \"--\", \"linewidth\": 1, \"color\": \"k\"}\n",
    "    sns.regplot(data=df_s, x=x, y=y, ax=axs[i], ci=95, scatter_kws=scatter_kws,\n",
    "                line_kws=line_kws)\n",
    "    axs[i].set_xlabel(\"\")\n",
    "    axs[i].set_ylabel(\"\")\n",
    "    axs[i].spines[['right', 'top']].set_visible(False)\n",
    "    axs[i].set_xlim([15, 90])\n",
    "    axs[i].set_ylim([-10, 750])\n",
    "\n",
    "    # to print p and r values\n",
    "    X = sm.add_constant(df_s[x]) \n",
    "    model = sm.GLS(df_s[y], X)\n",
    "    results = model.fit()\n",
    "    print(results.pvalues)\n",
    "    # axs[i][j].set_title(f\"R_const:{round(results.params.const, 3)}, R_ii:{round(results.params.II, 3)}\\n p_const:{round(results.pvalues.const, 3)}, p_ii:{round(results.pvalues.II, 3)}\", fontsize=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connectivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epochs dictionary (some needs concatenating)\n",
    "epochs_folder = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg1'\n",
    "epochs_file = {}\n",
    "for f in sorted(os.listdir(epochs_folder)):\n",
    "    file = os.path.join(epochs_folder, f)\n",
    "    if file.endswith(\"-epo.fif\") and '697' not in file and '750' not in file and '853' not in file and '841' not in file:\n",
    "        epochs_file[f'{file[-11:-8]}'] = file\n",
    "\n",
    "# create dictionary for stc objects\n",
    "key_stims = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240',\n",
    "        'GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240'] \n",
    "po_stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "method = \"dSPM\"\n",
    "snr = 3.0\n",
    "lambda2 = 1.0 / snr**2\n",
    "stcs_dict = {}\n",
    "\n",
    "for subject in tqdm(list(epochs_file.keys())):\n",
    "    \n",
    "    # reading the epoch\n",
    "    epochs = mne.read_epochs(fname=epochs_file[subject], preload=True, verbose=False)\n",
    "    \n",
    "    # setting up the surface source space\n",
    "    src = mne.setup_source_space(f'0{subject}', spacing=\"oct6\", subjects_dir=subjects_dir, n_jobs=-1, verbose=None)\n",
    "\n",
    "    # setting up the boundary-element model (BEM) \n",
    "    bem_model = mne.make_bem_model(subject=f'0{subject}', ico=4, subjects_dir=subjects_dir, verbose=None)  \n",
    "    bem = mne.make_bem_solution(bem_model, verbose=False)\n",
    "\n",
    "    # aligning coordinate frame (coregistration MEG-MRI)\n",
    "    info = epochs.info \n",
    "    coreg = Coregistration(info, f'0{subject}', subjects_dir, fiducials='auto')\n",
    "    coreg.fit_fiducials(verbose=False)\n",
    "    coreg.fit_icp(n_iterations=40, nasion_weight=2.0, verbose=False) \n",
    "    coreg.omit_head_shape_points(distance=5.0 / 1000) \n",
    "    coreg.fit_icp(n_iterations=40, nasion_weight=10, verbose=False) \n",
    "\n",
    "    # Computing the forward solution\n",
    "    print(f'Computing the forward solution ...')\n",
    "    fwd = mne.make_forward_solution(info, trans=coreg.trans, src=src, bem=bem, meg=True,\n",
    "                                    eeg=False, mindist=5.0, n_jobs=None, verbose=False)\n",
    "\n",
    "    # Computing the regularized noise-covariance matrix (consider the notes)\n",
    "    print(f'Estimate the noise covariance of the recording ...')\n",
    "    noise_cov = mne.compute_covariance(epochs[po_stims], tmax=0.0, method=(\"empirical\", \"shrunk\"),\n",
    "                                        verbose=False)\n",
    "    \n",
    "    # Computing the minimum-norm inverse solution\n",
    "    print(f'Computing the minimum-norm inverse solution ...')\n",
    "    inverse_operator = make_inverse_operator(info, fwd, noise_cov, loose=0.2, depth=0.8, verbose=False)\n",
    "\n",
    "    # Compute source estimate object\n",
    "    print(f'Computing and saving the source estimate object ...')\n",
    "    stc_dict = {}\n",
    "    for key in key_stims:\n",
    "        stc = apply_inverse_epochs(epochs[key], inverse_operator, lambda2,\n",
    "                                    method=method, pick_ori=None, verbose=False)\n",
    "        stc_dict[key] = stc\n",
    "        \n",
    "    stcs_dict[subject] = stc_dict\n",
    "\n",
    "\n",
    "fname_fsaverage_src = '/Users/payamsadeghishabestari/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif'\n",
    "src_to = mne.read_source_spaces(fname_fsaverage_src)\n",
    "labels = mne.read_labels_from_annot(subject='fsaverage', parc=\"aparc\", subjects_dir=None, verbose=False)[:-1]\n",
    "\n",
    "## create dictionary for labels_ts\n",
    "labels_tss_dict = {} \n",
    "for subject in tqdm(list(stcs_dict.keys())):\n",
    "    labels_ts_dict = {}\n",
    "    for key in key_stims:\n",
    "        ## morph them to fsaverage\n",
    "        stc = stcs_dict[subject][key]\n",
    "        morph = mne.compute_source_morph(stc[0], subject_from=f'0{subject}', subject_to=\"fsaverage\",\n",
    "                                        subjects_dir=subjects_dir, src_to=src_to)\n",
    "        stc_morph = []\n",
    "        for stc_ep in stc: \n",
    "            stc_morph.append(morph.apply(stc_ep))\n",
    "        \n",
    "        ## extract time labels\n",
    "        labels_ts = mne.extract_label_time_course(stc_morph, labels, src=src_to,\n",
    "                                                return_generator=False, verbose=False)\n",
    "        labels_ts_dict[key] = np.array(labels_ts)\n",
    "    labels_tss_dict[subject] = labels_ts_dict\n",
    "\n",
    "## save the dictionary\n",
    "file_path = '/Users/payamsadeghishabestari/KI_MEG/stcs/labels_ts_dict.pickle'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(labels_tss_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dictionary and compute connectivity\n",
    "file_path = '/Users/payamsadeghishabestari/KI_MEG/stcs/labels_ts_dict.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    labels_ts_dict = pickle.load(file)\n",
    "\n",
    "key_stims = ['GP60_i0', 'GP60_i60', 'GP60_i120', 'GP60_i240',\n",
    "        'GP70_i0', 'GP70_i60', 'GP70_i120', 'GP70_i240'] \n",
    "labels = mne.read_labels_from_annot(subject='fsaverage', parc=\"aparc\", subjects_dir=None, verbose=False)[:-1]\n",
    "lb_names = [lb.name for lb in labels]\n",
    "sfreq = 250\n",
    "(tmin, tmax) = (0.3, None)\n",
    "method = \"wpli\" # I would suggest pli, wpli or plv\n",
    "mode = \"multitaper\"\n",
    "Freq_Bands = {\"theta\": [4.0, 8.0], \"alpha\": [8.0, 13.0], \"beta\": [13.0, 30.0]}\n",
    "min_freq = np.min(list(Freq_Bands.values()))\n",
    "max_freq = np.max(list(Freq_Bands.values()))\n",
    "freqs = np.linspace(min_freq, max_freq, int((max_freq - min_freq) * 4 + 1))\n",
    "fmins = tuple([list(Freq_Bands.values())[f][0] for f in range(len(Freq_Bands))])\n",
    "fmaxs = tuple([list(Freq_Bands.values())[f][1] for f in range(len(Freq_Bands))])\n",
    "low_tri_idxs = np.tril_indices(len(labels), k=1)\n",
    "\n",
    "con_dict = {}\n",
    "for subject in tqdm(list(labels_ts_dict.keys())):\n",
    "    con_sub_dict = {}\n",
    "    for key in key_stims:\n",
    "        con_sub_sub_dict = {}\n",
    "        data = labels_ts_dict[subject][key]\n",
    "        for fmin, fmax, freq_band in zip(fmins, fmaxs, list(Freq_Bands.keys())):\n",
    "            con = spectral_connectivity_epochs(data=data, names=lb_names, method=method, sfreq=sfreq,\n",
    "                                                mode=mode, fmin=fmin, fmax=fmax, cwt_freqs=freqs, \n",
    "                                                faverage=False, tmin=tmin, tmax=tmax, verbose=False)\n",
    "            con_data = con.get_data(output=\"dense\")[:,:,0]\n",
    "            con_sub_sub_dict[freq_band] = con_data[low_tri_idxs]\n",
    "        con_sub_dict[key] = con_sub_sub_dict\n",
    "    con_dict[subject] = con_sub_dict\n",
    "\n",
    "# reshape the dictionary first\n",
    "nl_dict = {f: {} for f in list(Freq_Bands.keys())}\n",
    "for key in list(nl_dict.keys()):\n",
    "    nl_dict[key] = {'GP60_i0': [], 'GP60_i60': [], 'GP60_i120': [], 'GP60_i240': [],\n",
    "        'GP70_i0': [], 'GP70_i60': [], 'GP70_i120': [], 'GP70_i240': []}\n",
    "\n",
    "for freq_band in list(Freq_Bands.keys()):\n",
    "    for key in key_stims:\n",
    "        for subject in list(con_dict.keys()):\n",
    "            nl_dict[freq_band][key].append(con_dict[subject][key][freq_band])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stats (change indexes to compare)\n",
    "freq_band = \"alpha\"\n",
    "mode = \"average\" # or average\n",
    "(p_thr, alpha) = (0.05, 0.05)\n",
    "keys1 = np.array(key_stims)[[1, 5]]\n",
    "keys2 = np.array(key_stims)[[3, 7]]\n",
    "\n",
    "\n",
    "nl_60_data = []\n",
    "nl_70_data = []\n",
    "for key in keys1:\n",
    "    nl_60_data.append(np.array(nl_dict[freq_band][key]))\n",
    "for key in keys2:\n",
    "    nl_70_data.append(np.array(nl_dict[freq_band][key]))\n",
    "\n",
    "if mode == \"average\":\n",
    "    nl_60_data = np.array(nl_60_data).mean(axis=0)\n",
    "    nl_70_data = np.array(nl_70_data).mean(axis=0)\n",
    "if mode == \"concat\":\n",
    "    nl_60_data = np.concatenate(nl_60_data, axis=0)\n",
    "    nl_70_data = np.concatenate(nl_70_data, axis=0)\n",
    "\n",
    "stat, p_values = ttest_ind(nl_60_data, nl_70_data, permutations=0, random_state=42)\n",
    "p_values[np.where(p_values.astype(str)==\"nan\")[0]] = 0\n",
    "reject_null, p_corrected, _, _ = sm.stats.multipletests(pvals=p_values, alpha=alpha,\n",
    "                                                            method=\"fdr_bh\")\n",
    "label_idxs = []\n",
    "indexes = [i for i, val in enumerate(p_corrected) if val < p_thr and val != 0]\n",
    "if len(indexes) == 0:\n",
    "    print(f\"No statistical difference between brain labels for method {method}\")\n",
    "else:\n",
    "    for idx in indexes:\n",
    "        label_idxs.append((low_tri_idxs[0][idx], low_tri_idxs[1][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "n_labels = len(labels)\n",
    "control_avg_vector = np.mean(nl_60_data, axis=0)\n",
    "control_avg_graph = np.zeros(shape=(n_labels, n_labels))\n",
    "control_avg_graph[low_tri_idxs] = control_avg_vector\n",
    "control_avg_graph = control_avg_graph + control_avg_graph.T\n",
    "\n",
    "case_avg_vector = np.mean(nl_70_data, axis=0)\n",
    "case_avg_graph = np.zeros(shape=(n_labels, n_labels))\n",
    "case_avg_graph[low_tri_idxs] = case_avg_vector\n",
    "case_avg_graph = case_avg_graph + case_avg_graph.T\n",
    "\n",
    "diff_graph = control_avg_graph - case_avg_graph\n",
    "\n",
    "node_coords = []\n",
    "for label in labels:\n",
    "    if label.hemi == 'lh':\n",
    "        hemi = 0\n",
    "    if label.hemi == 'rh':\n",
    "        hemi = 1\n",
    "    center_vertex = label.center_of_mass(subject='fsaverage', \n",
    "                                        restrict_vertices=False, \n",
    "                                        subjects_dir=None)\n",
    "    mni_pos = mne.vertex_to_mni(center_vertex, hemis=hemi,\n",
    "                            subject='fsaverage', subjects_dir=None)\n",
    "    node_coords.append(mni_pos)\n",
    "\n",
    "node_coords = np.array(node_coords)\n",
    "ticks = [lb.name for lb in labels]\n",
    "\n",
    "diff_graph = control_avg_graph - case_avg_graph\n",
    "zero_matrix = np.zeros(shape=(n_labels, n_labels))\n",
    "for i, j in label_idxs:\n",
    "    zero_matrix[i][j] = diff_graph[i][j]\n",
    "stat_graph = zero_matrix + zero_matrix.T  \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11, 5))\n",
    "plot_connectome(adjacency_matrix=stat_graph, node_coords=node_coords, display_mode=\"lzry\",\n",
    "                node_color='k', node_size=20, axes=ax, colorbar=False,\n",
    "                edge_threshold=\"99%\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preparing the dataframe for anova pulse only\n",
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv\")\n",
    "# remove some subjects\n",
    "mask = df['subject ID'].isin([697, 750, 853, 841]) # 841 is just for fun\n",
    "df = df[~mask]\n",
    "# take only pulse only\n",
    "mask_po = df[\"Stimulus\"].isin([\"PO60_75\", \"PO60_80\", \"PO60_85\", \"PO60_90\", \"PO60_95\",\n",
    "                                \"PO70_75\", \"PO70_80\", \"PO70_85\", \"PO70_90\", \"PO70_95\"])\n",
    "df = df[mask_po]\n",
    "# create two new columns PL and BBN\n",
    "def check_BBN(string):\n",
    "    if 'PO60' in string:\n",
    "        return 60\n",
    "    elif 'PO70' in string:\n",
    "        return 70\n",
    "def check_PL(string):\n",
    "    return string[-2:]   \n",
    "df['BBN'] = df['Stimulus'].apply(check_BBN)\n",
    "df['PL'] = df['Stimulus'].apply(check_PL)\n",
    "# rename latency columns\n",
    "df = df.rename(columns={\"EOG peak latency\": \"EOG_peak_latency\", \"EOG peak\": \"EOG_peak\",\n",
    "                        \"peak value (30ms)\": \"peak_value_30ms\", \"subject ID\": \"ID\"})\n",
    "df_eog = df[df[\"Hemisphere\"]==\"rh\"]\n",
    "df_rh = df[df[\"Hemisphere\"]==\"rh\"]\n",
    "df_lh = df[df[\"Hemisphere\"]==\"lh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eog latency anova\n",
    "model_eog_lat = ols(formula='EOG_peak_latency ~ C(PL) + C(BBN) + C(PL):C(BBN)',\n",
    "            data=df_eog).fit()\n",
    "table_eog_lat = sm.stats.anova_lm(model_eog_lat, typ=2)\n",
    "aovrm2way_eog_lat = AnovaRM(df_eog, \"EOG_peak_latency\", \"ID\", within=[\"PL\", \"BBN\"]).fit()\n",
    "\n",
    "# lh latency anova\n",
    "model_lh_lat = ols(formula='latency ~ C(PL) + C(BBN) + C(PL):C(BBN)',\n",
    "            data=df_lh).fit()\n",
    "table_lh_lat = sm.stats.anova_lm(model_lh_lat, typ=2)\n",
    "aovrm2way_lh_lat = AnovaRM(df_lh, \"latency\", \"ID\", within=[\"PL\", \"BBN\"]).fit()\n",
    "\n",
    "# rh latency anova\n",
    "model_rh_lat = ols(formula='latency ~ C(PL) + C(BBN) + C(PL):C(BBN)',\n",
    "            data=df_rh).fit()\n",
    "table_rh_lat = sm.stats.anova_lm(model_rh_lat, typ=2)\n",
    "aovrm2way_rh_lat = AnovaRM(df_rh, \"latency\", \"ID\", within=[\"PL\", \"BBN\"]).fit()\n",
    "\n",
    "# eog peak amplitude\n",
    "model_eog_peak = ols(formula='EOG_peak ~ C(PL) + C(BBN) + C(PL):C(BBN)',\n",
    "            data=df_eog).fit()\n",
    "table_eog_peak = sm.stats.anova_lm(model_eog_peak, typ=2)\n",
    "aovrm2way_eog_peak = AnovaRM(df_eog, \"EOG_peak\", \"ID\", within=[\"PL\", \"BBN\"]).fit()\n",
    "\n",
    "# lh peak amplitude\n",
    "model_lh_peak = ols(formula='peak_value_30ms ~ C(PL) + C(BBN) + C(PL):C(BBN)',\n",
    "            data=df_lh).fit()\n",
    "table_lh_peak = sm.stats.anova_lm(model_lh_peak, typ=2)\n",
    "aovrm2way_lh_lat = AnovaRM(df_lh, \"peak_value_30ms\", \"ID\", within=[\"PL\", \"BBN\"]).fit()\n",
    "\n",
    "# rh peak amplitude\n",
    "model_rh_peak = ols(formula='peak_value_30ms ~ C(PL) + C(BBN) + C(PL):C(BBN)',\n",
    "            data=df_rh).fit()\n",
    "table_rh_peak = sm.stats.anova_lm(model_rh_peak, typ=2)\n",
    "aovrm2way_rh_lat = AnovaRM(df_rh, \"peak_value_30ms\", \"ID\", within=[\"PL\", \"BBN\"]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_eog_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_rh[df_rh[\"BBN\"]==60]\n",
    "tukey = MultiComparison(data=df_sub['peak_value_30ms'], groups=df_sub['PL']).tukeyhsd()\n",
    "tukey.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA on Gap Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preparing the dataframe for anova gap only\n",
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv\")\n",
    "# remove some subjects\n",
    "mask = df['subject ID'].isin([697, 750, 853, 841]) # 841 is just for fun\n",
    "df = df[~mask]\n",
    "# take only pulse only\n",
    "mask_po = df[\"Stimulus\"].isin([\"GO_60\", \"GO_70\"])\n",
    "df = df[mask_po]\n",
    "# create two new columns PL and BBN\n",
    "def check_BBN(string):\n",
    "    if '60' in string:\n",
    "        return 60\n",
    "    elif '70' in string:\n",
    "        return 70\n",
    "df['BBN'] = df['Stimulus'].apply(check_BBN)\n",
    "# rename columns\n",
    "df = df.rename(columns={\"peak value (30ms)\": \"peak_value_30ms\", \"subject ID\": \"ID\"})\n",
    "\n",
    "df_rh_60 = df[(df[\"Hemisphere\"]==\"rh\") & (df[\"BBN\"]==60)]\n",
    "df_lh_60 = df[(df[\"Hemisphere\"]==\"lh\") & (df[\"BBN\"]==60)]\n",
    "df_rh_70 = df[(df[\"Hemisphere\"]==\"rh\") & (df[\"BBN\"]==70)]\n",
    "df_lh_70 = df[(df[\"Hemisphere\"]==\"lh\") & (df[\"BBN\"]==70)]\n",
    "\n",
    "print(f_oneway(df_rh_60[\"peak_value_30ms\"], df_lh_60[\"peak_value_30ms\"]))\n",
    "print(f_oneway(df_rh_70[\"peak_value_30ms\"], df_lh_70[\"peak_value_30ms\"]))\n",
    "\n",
    "##\n",
    "print(f_oneway(df_rh_60[\"EOG peak\"], df_rh_70[\"EOG peak\"]))\n",
    "print(f_oneway(df_lh_60[\"peak_value_30ms\"], df_lh_70[\"peak_value_30ms\"]))\n",
    "print(f_oneway(df_rh_60[\"peak_value_30ms\"], df_rh_70[\"peak_value_30ms\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f_oneway(df_rh_60[\"EOG peak latency\"], df_rh_70[\"EOG peak latency\"]))\n",
    "print(f_oneway(df_lh_60[\"latency\"], df_lh_70[\"latency\"]))\n",
    "print(f_oneway(df_rh_60[\"latency\"], df_rh_70[\"latency\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_oneway(df_rh_60[\"EOG peak\"], df_rh_70[\"EOG peak\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = round(df_rh_70[\"latency\"].mean(), 2)\n",
    "std = round(df_rh_70[\"latency\"].std(), 1)\n",
    "print(f\"{mean}, {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preparing the dataframe for scatter plot\n",
    "df = pd.read_csv(\"/Users/payamsadeghishabestari/KI_MEG/dataframes/tinmeg1_transverstemporal.csv\")\n",
    "# remove some subjects\n",
    "mask = df['subject ID'].isin([697, 750, 853, 841]) # 841 is just for fun\n",
    "df = df[~mask]\n",
    "df_rh_60 = df[(df[\"Stimulus\"]==\"PO60_90\") & (df[\"Hemisphere\"]==\"rh\")]\n",
    "df_lh_60 = df[(df[\"Stimulus\"]==\"PO60_90\") & (df[\"Hemisphere\"]==\"lh\")]\n",
    "df_rh_70 = df[(df[\"Stimulus\"]==\"PO70_90\") & (df[\"Hemisphere\"]==\"rh\")]\n",
    "df_lh_70 = df[(df[\"Stimulus\"]==\"PO70_90\") & (df[\"Hemisphere\"]==\"lh\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(11, 5))\n",
    "kwargs={\"color\": \"b\"}\n",
    "sns.scatterplot(data=None, x=df_lh_60[\"peak value (30ms)\"], y=df_lh_60[\"EOG peak\"], ax=axs[0], **kwargs)\n",
    "kwargs={\"color\": \"r\"}\n",
    "sns.scatterplot(data=None, x=df_rh_60[\"peak value (30ms)\"], y=df_rh_60[\"EOG peak\"], ax=axs[0], **kwargs)\n",
    "\n",
    "kwargs={\"color\": \"b\"}\n",
    "sns.scatterplot(data=None, x=df_lh_70[\"peak value (30ms)\"], y=df_lh_70[\"EOG peak\"], ax=axs[1], **kwargs)\n",
    "kwargs={\"color\": \"r\"}\n",
    "sns.scatterplot(data=None, x=df_rh_70[\"peak value (30ms)\"], y=df_rh_70[\"EOG peak\"], ax=axs[1], **kwargs)\n",
    "\n",
    "axs[0].set_title(\"BBN 60\")\n",
    "axs[1].set_title(\"BBN 70\")\n",
    "axs[0].set_ylim([0, 80])\n",
    "axs[1].set_ylim([0, 80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connectivity in Gap only between right and left transverse temporal (and all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epochs dictionary (some needs concatenating)\n",
    "epochs_folder = '/Users/payamsadeghishabestari/KI_MEG/epochs/tinmeg1'\n",
    "epochs_file = {}\n",
    "for f in sorted(os.listdir(epochs_folder)):\n",
    "    file = os.path.join(epochs_folder, f)\n",
    "    if file.endswith(\"-epo.fif\") and '697' not in file and '750' not in file and '853' not in file and '841' not in file:\n",
    "        epochs_file[f'{file[-11:-8]}'] = file\n",
    "\n",
    "# create dictionary for stc objects\n",
    "key_stims = [\"GO_60\", \"GO_70\"] \n",
    "po_stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "subjects_dir = '/Applications/freesurfer/7.4.1/subjects'\n",
    "method = \"dSPM\"\n",
    "snr = 3.0\n",
    "lambda2 = 1.0 / snr**2\n",
    "stcs_dict = {}\n",
    "\n",
    "for subject in tqdm(list(epochs_file.keys())):\n",
    "    \n",
    "    # reading the epoch\n",
    "    epochs = mne.read_epochs(fname=epochs_file[subject], preload=True, verbose=False)\n",
    "    \n",
    "    # setting up the surface source space\n",
    "    src = mne.setup_source_space(f'0{subject}', spacing=\"oct6\", subjects_dir=subjects_dir, n_jobs=-1, verbose=None)\n",
    "\n",
    "    # setting up the boundary-element model (BEM) \n",
    "    bem_model = mne.make_bem_model(subject=f'0{subject}', ico=4, subjects_dir=subjects_dir, verbose=None)  \n",
    "    bem = mne.make_bem_solution(bem_model, verbose=False)\n",
    "\n",
    "    # aligning coordinate frame (coregistration MEG-MRI)\n",
    "    info = epochs.info \n",
    "    coreg = Coregistration(info, f'0{subject}', subjects_dir, fiducials='auto')\n",
    "    coreg.fit_fiducials(verbose=False)\n",
    "    coreg.fit_icp(n_iterations=40, nasion_weight=2.0, verbose=False) \n",
    "    coreg.omit_head_shape_points(distance=5.0 / 1000) \n",
    "    coreg.fit_icp(n_iterations=40, nasion_weight=10, verbose=False) \n",
    "\n",
    "    # Computing the forward solution\n",
    "    print(f'Computing the forward solution ...')\n",
    "    fwd = mne.make_forward_solution(info, trans=coreg.trans, src=src, bem=bem, meg=True,\n",
    "                                    eeg=False, mindist=5.0, n_jobs=None, verbose=False)\n",
    "\n",
    "    # Computing the regularized noise-covariance matrix (consider the notes)\n",
    "    print(f'Estimate the noise covariance of the recording ...')\n",
    "    noise_cov = mne.compute_covariance(epochs[po_stims], tmax=0.0, method=(\"empirical\", \"shrunk\"),\n",
    "                                        verbose=False)\n",
    "    \n",
    "    # Computing the minimum-norm inverse solution\n",
    "    print(f'Computing the minimum-norm inverse solution ...')\n",
    "    inverse_operator = make_inverse_operator(info, fwd, noise_cov, loose=0.2, depth=0.8, verbose=False)\n",
    "\n",
    "    # Compute source estimate object\n",
    "    print(f'Computing and saving the source estimate object ...')\n",
    "    stc_dict = {}\n",
    "    for key in key_stims:\n",
    "        stc = apply_inverse_epochs(epochs[key], inverse_operator, lambda2,\n",
    "                                    method=method, pick_ori=None, verbose=False)\n",
    "        stc_dict[key] = stc\n",
    "        \n",
    "    stcs_dict[subject] = stc_dict\n",
    "\n",
    "\n",
    "fname_fsaverage_src = '/Users/payamsadeghishabestari/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif'\n",
    "src_to = mne.read_source_spaces(fname_fsaverage_src)\n",
    "labels = mne.read_labels_from_annot(subject='fsaverage', parc=\"aparc\", subjects_dir=None, verbose=False)[:-1]\n",
    "\n",
    "## create dictionary for labels_ts\n",
    "labels_tss_dict = {} \n",
    "for subject in tqdm(list(stcs_dict.keys())):\n",
    "    labels_ts_dict = {}\n",
    "    for key in key_stims:\n",
    "        ## morph them to fsaverage\n",
    "        stc = stcs_dict[subject][key]\n",
    "        morph = mne.compute_source_morph(stc[0], subject_from=f'0{subject}', subject_to=\"fsaverage\",\n",
    "                                        subjects_dir=subjects_dir, src_to=src_to)\n",
    "        stc_morph = []\n",
    "        for stc_ep in stc: \n",
    "            stc_morph.append(morph.apply(stc_ep))\n",
    "        \n",
    "        ## extract time labels\n",
    "        labels_ts = mne.extract_label_time_course(stc_morph, labels, src=src_to,\n",
    "                                                return_generator=False, verbose=False)\n",
    "        labels_ts_dict[key] = np.array(labels_ts)\n",
    "    labels_tss_dict[subject] = labels_ts_dict\n",
    "\n",
    "## save the dictionary\n",
    "file_path = '/Users/payamsadeghishabestari/KI_MEG/stcs/labels_ts_go_dict.pickle'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(labels_tss_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dictionary and compute connectivity\n",
    "file_path = '/Users/payamsadeghishabestari/KI_MEG/stcs/labels_ts_go_dict.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    labels_ts_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = labels_ts_dict[\"539\"][\"GO_60\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dictionary and compute connectivity\n",
    "file_path = '/Users/payamsadeghishabestari/KI_MEG/stcs/labels_ts_go_dict.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    labels_ts_dict = pickle.load(file)\n",
    "\n",
    "key_stims = [\"GO_60\", \"GO_70\"] \n",
    "labels = mne.read_labels_from_annot(subject='fsaverage', parc=\"aparc\", subjects_dir=None, verbose=False)[:-1]\n",
    "lb_names = [lb.name for lb in labels]\n",
    "sfreq = 250\n",
    "(tmin, tmax) = (0.3, None)\n",
    "method = \"wpli\" # I would suggest pli, wpli or plv\n",
    "mode = \"multitaper\"\n",
    "Freq_Bands = {\"theta\": [4.0, 8.0], \"alpha\": [8.0, 13.0], \"beta\": [13.0, 30.0], \"gamma\": [30.0, 80.0]}\n",
    "min_freq = np.min(list(Freq_Bands.values()))\n",
    "max_freq = np.max(list(Freq_Bands.values()))\n",
    "freqs = np.linspace(min_freq, max_freq, int((max_freq - min_freq) * 4 + 1))\n",
    "fmins = tuple([list(Freq_Bands.values())[f][0] for f in range(len(Freq_Bands))])\n",
    "fmaxs = tuple([list(Freq_Bands.values())[f][1] for f in range(len(Freq_Bands))])\n",
    "low_tri_idxs = np.tril_indices(len(labels), k=-1)\n",
    "\n",
    "con_dict = {}\n",
    "for subject in tqdm(list(labels_ts_dict.keys())):\n",
    "    con_sub_dict = {}\n",
    "    for key in key_stims:\n",
    "        con_sub_sub_dict = {}\n",
    "        data = labels_ts_dict[subject][key]\n",
    "        for fmin, fmax, freq_band in zip(fmins, fmaxs, list(Freq_Bands.keys())):\n",
    "            con = spectral_connectivity_epochs(data=data, names=lb_names, method=method, sfreq=sfreq,\n",
    "                                                mode=mode, fmin=fmin, fmax=fmax, cwt_freqs=freqs, \n",
    "                                                faverage=True, tmin=tmin, tmax=tmax, verbose=False)\n",
    "            con_data = con.get_data(output=\"dense\")[:,:,0]\n",
    "            con_sub_sub_dict[freq_band] = con_data[low_tri_idxs]\n",
    "        con_sub_dict[key] = con_sub_sub_dict\n",
    "    con_dict[subject] = con_sub_dict\n",
    "\n",
    "# reshape the dictionary first\n",
    "nl_dict = {f: {} for f in list(Freq_Bands.keys())}\n",
    "for key in list(nl_dict.keys()):\n",
    "    nl_dict[key] = {\"GO_60\": [], \"GO_70\": []}\n",
    "\n",
    "for freq_band in list(Freq_Bands.keys()):\n",
    "    for key in key_stims:\n",
    "        for subject in list(con_dict.keys()):\n",
    "            nl_dict[freq_band][key].append(con_dict[subject][key][freq_band])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stats (change indexes to compare)\n",
    "freq_band = \"beta\"\n",
    "mode = \"average\" # or average\n",
    "(p_thr, alpha) = (0.05, 0.05)\n",
    "keys1 = np.array(key_stims)[[0]]\n",
    "keys2 = np.array(key_stims)[[1]]\n",
    "idx1 = lb_names.index(\"transversetemporal-lh\")\n",
    "idx2 = lb_names.index(\"transversetemporal-rh\")\n",
    "\n",
    "nl_60_data = []\n",
    "nl_70_data = []\n",
    "for key in keys1:\n",
    "    nl_60_data.append(np.array(nl_dict[freq_band][key]))\n",
    "for key in keys2:\n",
    "    nl_70_data.append(np.array(nl_dict[freq_band][key]))\n",
    "\n",
    "if mode == \"average\":\n",
    "    nl_60_data = np.array(nl_60_data).mean(axis=0)\n",
    "    nl_70_data = np.array(nl_70_data).mean(axis=0)\n",
    "if mode == \"concat\":\n",
    "    nl_60_data = np.concatenate(nl_60_data, axis=0)\n",
    "    nl_70_data = np.concatenate(nl_70_data, axis=0)\n",
    "\n",
    "stat, p_values = ttest_ind(nl_60_data, nl_70_data, permutations=0, random_state=42)\n",
    "p_values[np.where(p_values.astype(str)==\"nan\")[0]] = 0\n",
    "\n",
    "index = np.where((low_tri_idxs[0]== idx2) & (low_tri_idxs[1] == idx1))[0][0]\n",
    "print(p_values[index])\n",
    "\n",
    "reject_null, p_corrected, _, _ = sm.stats.multipletests(pvals=p_values, alpha=alpha,\n",
    "                                                            method=\"fdr_bh\")\n",
    "label_idxs = []\n",
    "indexes = [i for i, val in enumerate(p_corrected) if val < p_thr and val != 0]\n",
    "if len(indexes) == 0:\n",
    "    print(f\"No statistical difference between brain labels for method {method}\")\n",
    "else:\n",
    "    for idx in indexes:\n",
    "        label_idxs.append((low_tri_idxs[0][idx], low_tri_idxs[1][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,4))\n",
    "palette_color = ['#1f77b4', '#d62728'] \n",
    "sns.boxplot(data=[nl_60_data[:,index], nl_70_data[:,index]], width=0.8, fill=False, gap=.1, linewidth=2,\n",
    "            saturation=0.75, palette=palette_color, ax=ax)\n",
    "sns.stripplot(data=[nl_60_data[:,index], nl_70_data[:,index]],\n",
    "            dodge=False, size=3, palette=palette_color, ax=ax, legend=False)\n",
    "ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did Pulse level elicited TT activity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### eog check\n",
    "fig, axs = plt.subplots(1, 1, figsize=(6, 3))\n",
    "time_array = np.linspace(-300, 300, 151)\n",
    "stims = ['PO60_70', 'PO60_75', 'PO60_80', 'PO60_85', 'PO60_90', 'PO60_95']\n",
    "color = '#ff7f0e'\n",
    "lw = 0.5\n",
    "for stim in stims[:-1]:\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6,\n",
    "            linewidth=lw, label=stim, color=color)\n",
    "    lw += 0.4\n",
    "for stim in stims[-1:]:\n",
    "    axs.plot(time_array, grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6,\n",
    "            linewidth=lw, label=stim, color='k')\n",
    "    \n",
    "axs.axvspan(50, 180, alpha=0.4, color='lightgrey')\n",
    "axs.legend(fontsize=9, frameon=False, bbox_to_anchor=(0.5, 0.1, 0.6, 0.6))\n",
    "axs.spines['top'].set_visible(False); axs.spines['right'].set_visible(False)\n",
    "for i in [-200, -100, 100, 200, 300]:\n",
    "    axs.vlines(i, -10, 60, colors='black',linestyles=':', linewidth=0.5)\n",
    "axs.vlines(0, -10, 60, colors='black',linestyles='--')\n",
    "axs.set_ylabel(f'EOG amplitude at 70 dB (µv)')\n",
    "axs.set_xlabel(f'Time (ms)')\n",
    "axs.set_ylim([-10, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eog check\n",
    "stim = \"PO70_80\"\n",
    "scale = 10\n",
    "po_data = grand_ev_dict[stim].get_data(picks='EOG002')[0] * 1e6\n",
    "baseline_mean = po_data[25:75].mean()\n",
    "baseline_mad = np.mean(np.abs(po_data[25:75] - baseline_mean))\n",
    "po_data_peak = po_data[75:].min()\n",
    "if po_data_peak < (baseline_mean - scale * baseline_mad):\n",
    "    print(f\"{stim} elucidated eog response.\") \n",
    "else:\n",
    "    print(f\"{stim} did not elucidate eog response.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TT check\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed'\n",
    "stc_files_list_rh = {'PO60_70': [], 'PO60_75': [], 'PO60_80': [],\n",
    "                'PO70_75': [], 'PO70_80': []}\n",
    "stc_files_list_lh = {'PO60_70': [], 'PO60_75': [], 'PO60_80': [],\n",
    "                'PO70_75': [], 'PO70_80': []}\n",
    "events = ['PO60_70', 'PO60_75', 'PO60_80', 'PO70_75', 'PO70_80']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "\n",
    "for event in events:\n",
    "    for filename in sorted(os.listdir(directory)): \n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f: # or -rh\n",
    "                stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "                rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "                lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "                stc_files_list_rh[event].append(rh_data)\n",
    "                stc_files_list_lh[event].append(lh_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TT check\n",
    "stim = \"PO70_75\"\n",
    "scale = 10\n",
    "tt_data = np.squeeze(np.array(stc_files_list_lh[stim])).mean(axis=0)\n",
    "baseline_mean = tt_data[25:75].mean()\n",
    "baseline_mad = np.mean(np.abs(tt_data[25:75] - baseline_mean))\n",
    "tt_data_peak = tt_data[75:].max()\n",
    "if tt_data_peak > (baseline_mean + scale * baseline_mad):\n",
    "    print(f\"{stim} elucidated eog response.\") \n",
    "else:\n",
    "    print(f\"{stim} did not elucidate eog response.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whether you capture evoked responses even in the non-blinkers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_id in list(epochs_file.keys()):\n",
    "    if sub_id == [\"861\", \"856\", \"850\", \"847\", \"845\", \"836\", \"750\"]:\n",
    "        ev = mne.read_epochs(fname=epochs_file[sub_id], verbose=False).average(picks=['eog'], by_event_type=True)\n",
    "        ev[4].plot(picks=\"EOG002\", titles=sub_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = \"750\"\n",
    "stc_files_list_rh = {'PO60_90': []}\n",
    "stc_files_list_lh = {'PO60_90': []}\n",
    "events = ['PO60_90']\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc')[:-1] # 68 labels\n",
    "fs_dir = fetch_fsaverage(verbose=False)\n",
    "src_fname = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "src = mne.read_source_spaces(src_fname, verbose=False)\n",
    "directory = '/Users/payamsadeghishabestari/KI_MEG/stcs/tinmeg1_morphed' \n",
    "\n",
    "for event in events:\n",
    "    for filename in sorted(os.listdir(directory)): \n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f) and f.endswith(\"-lh.stc\") and event in f: # or -rh\n",
    "            if f[58:61]==sub_id:\n",
    "                stc = mne.read_source_estimate(fname=f, subject='fsaverage')\n",
    "                rh_data = stc.extract_label_time_course(brain_labels[-1], src, mode='mean', verbose=False)\n",
    "                lh_data = stc.extract_label_time_course(brain_labels[-2], src, mode='mean', verbose=False)\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12,3))\n",
    "                colors = ['#1f77b4', '#d62728']\n",
    "                axs[0].plot(np.linspace(-300, 300, 151), lh_data[0], label=event, color=colors[0])\n",
    "                axs[1].plot(np.linspace(-300, 300, 151), rh_data[0], label=event, color=colors[1])\n",
    "                axs[0].set_ylim([-1, 10])\n",
    "                axs[1].set_ylim([-1, 10])\n",
    "                axs[0].set_ylabel(f\"{sub_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
